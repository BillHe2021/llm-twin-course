{
    "Post_0": {
        "text": "\ud83d\udd04 \ud835\ude08\ud835\ude33\ud835\ude26 \ud835\ude3a\ud835\ude30\ud835\ude36 \ud835\ude26\ud835\ude39\ud835\ude31\ud835\ude2d\ud835\ude30\ud835\ude33\ud835\ude2a\ud835\ude2f\ud835\ude28 \ud835\ude34\ud835\ude26\ud835\ude33\ud835\ude37\ud835\ude26\ud835\ude33\ud835\ude2d\ud835\ude26\ud835\ude34\ud835\ude34 \ud835\ude34\ud835\ude30\ud835\ude2d\ud835\ude36\ud835\ude35\ud835\ude2a\ud835\ude30\ud835\ude2f\ud835\ude34 \ud835\ude27\ud835\ude30\ud835\ude33 \ud835\ude33\ud835\ude26\ud835\ude22\ud835\ude2d-\ud835\ude35\ud835\ude2a\ud835\ude2e\ud835\ude26 \ud835\ude25\ud835\ude22\ud835\ude35\ud835\ude22 \ud835\ude31\ud835\ude33\ud835\ude30\ud835\ude24\ud835\ude26\ud835\ude34\ud835\ude34\ud835\ude2a\ud835\ude2f\ud835\ude28?\nWith\nUpstash\n, a serverless key-value database, we were able to:\n\ud83c\udfaf Simplify our infrastructure setup\n\ud83c\udfaf Scale effortlessly with demand\n\ud83c\udfaf Ensure reliable data management\nThis producer logic diagram illustrates how we fetch news data from multiple sources, process it through ingestion threads, and then send it to Kafka for distribution. The entire setup is streamlined, thanks to Upstash's serverless architecture.\n\ud835\udc07\ud835\udc1e\ud835\udc2b\ud835\udc1e'\ud835\udc2c \ud835\udc1a \ud835\udc1b\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc24\ud835\udc1d\ud835\udc28\ud835\udc30\ud835\udc27 \ud835\udc28\ud835\udc1f \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc29\ud835\udc2b\ud835\udc28\ud835\udc1d\ud835\udc2e\ud835\udc1c\ud835\udc1e\ud835\udc2b \ud835\udc25\ud835\udc28\ud835\udc20\ud835\udc22\ud835\udc1c \ud83d\udc47 :\n\ud83d\udd3b Each data source has its own ingestion thread to fetch, parse, and format the news content.\n\ud83d\udd3bThe data is structured with Pydantic, providing a consistent format with fields like author, content, title, and date.\n\ud83d\udd3bThe Kafka Common Producer manages the data flow, sending it to the Kafka Cluster, where it's organized into various topics.\nThis \ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc26\ud835\udc25\ud835\udc22\ud835\udc27\ud835\udc1e\ud835\udc1d \ud835\udc1a\ud835\udc2b\ud835\udc1c\ud835\udc21\ud835\udc22\ud835\udc2d\ud835\udc1e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e allows us to handle real-time news data easily and ensures a scalable backend infrastructure.\nIf you're interested in building a real-time data pipeline, this setup can be a game-changer.\n\ud835\uddd5\ud835\ude02\ud835\ude01 \ud835\ude04\ud835\uddf5\ud835\uddf2\ud835\uddff\ud835\uddf2 \ud835\uddf6\ud835\ude00 \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\uddf0\ud835\uddfc\ud835\uddf1\ud835\uddf2?\n\ud83d\udd17 Check it out on:\nhttps://lnkd.in/dFrM55NX\n\u2193\u2193\u2193\n\ud83d\udd17 Full article:\nhttps://lnkd.in/dPSaDZd3",
        "image": "https://media.licdn.com/dms/image/D4D22AQGSUscgSvDXjw/feedshare-shrink_800/0/1714291433936?e=1717027200&v=beta&t=0TSI0Onbb7BDhWn4zChg6GGVGy55etpuLgN3QbqV3Qs"
    },
    "Post_1": {
        "text": "Hey,\nhashtag\n#\nLinkedin\ncommunity. Your guy needs help! \ud83d\udea8\nI'm having a hard time choosing between Knowledge Graphs and Graph Databases. \ud83d\ude35\u200d\ud83d\udcab\nIf there are any\nhashtag\n#\nML\nhashtag\n#\nSoftware\nhashtag\n#\nData\nhashtag\n#\nEngineers\nin my list that have worked with these concepts before, raise a hand in the comments below \ud83d\udc4b, I'd be super appreciative if I could have a chat about my dilemma.\nThanks in advance \ud83d\ude4f  !",
        "image": "https://media.licdn.com/dms/image/D4D22AQFfzuEsHieuCw/feedshare-shrink_800/0/1713945424464?e=1717027200&v=beta&t=ZvOZtXHfJ1kALbBRfxCh3a6mjlLXaNvD3p4hXr3S9DM"
    },
    "Post_2": {
        "text": "\ud835\ude1a\ud835\ude35\ud835\ude33\ud835\ude26\ud835\ude22\ud835\ude2e\ud835\ude2a\ud835\ude2f\ud835\ude28 \ud835\ude17\ud835\ude2a\ud835\ude31\ud835\ude26\ud835\ude2d\ud835\ude2a\ud835\ude2f\ud835\ude26\ud835\ude34 - \ud835\ude35\ud835\ude29\ud835\ude26 \ud835\ude24\ud835\ude29\ud835\ude26\ud835\ude33\ud835\ude33\ud835\ude3a \ud835\ude30\ud835\ude2f \ud835\ude35\ud835\ude30\ud835\ude31 \ud835\ude30\ud835\ude27 \ud835\ude22 \ud835\ude13\ud835\ude13\ud835\ude14 \ud835\ude31\ud835\ude33\ud835\ude30\ud835\ude2b\ud835\ude26\ud835\ude24\ud835\ude35\u00a0\ud83c\udf52\nLLM projects often deal with a massive, never-ending stream of data \u2013 think social media feeds, news updates, or code repositories.\n\ud835\udc00 \ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc26\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc29\ud835\udc22\ud835\udc29\ud835\udc1e\ud835\udc25\ud835\udc22\ud835\udc27\ud835\udc1e is built to handle this constant flow, preventing your LLM from blocking on huge data dumps. It processes and embeds information on the fly, keeping your model up-to-date.\nBytewax\noffers a central streaming flow, like the \"graph\" of your pipeline.\nThink input() -> process() -> output().\n\ud83d\ude0e In my case, I ingested posts, articles, and code from RabbitMQ, cleaned them, chunked them, and embedded them for a\nQdrant\nvector DB (feature store).\n\ud835\udc05\ud835\udc25\ud835\udc1e\ud835\udc31\ud835\udc22\ud835\udc1b\ud835\udc22\ud835\udc25\ud835\udc22\ud835\udc2d\ud835\udc32 \ud835\udc22\ud835\udc2c \ud835\udc0a\ud835\udc1e\ud835\udc32 \ud83d\udd11\nThe beauty of\nBytewax\n? It handles diverse data types.\nWe use a dispatcher to ensure posts, articles, and code are processed differently.\nPydantic\nmodels ensure data validation at each step. \ud83d\udc4c\nWhy the streaming pipeline with\nBytewax\n? \ud83d\udc47\n\ud83d\udd3b \ud835\udc0f\ud835\udc1e\ud835\udc2b\ud835\udc1f\ud835\udc28\ud835\udc2b\ud835\udc26\ud835\udc1a\ud835\udc27\ud835\udc1c\ud835\udc1e \ud835\udc0f\ud835\udc28\ud835\udc30\ud835\udc1e\ud835\udc2b: Built-in Rust for lightning speed!\n\ud83d\udd3b \ud835\udc0f\ud835\udc32\ud835\udc2d\ud835\udc21\ud835\udc28\ud835\udc27 \ud835\udc0f\ud835\udc1a\ud835\udc2b\ud835\udc1a\ud835\udc1d\ud835\udc22\ud835\udc2c\ud835\udc1e: Python bindings for all your favorite ML libraries.\n\ud83d\udd3b \ud835\udc04\ud835\udc1a\ud835\udc2c\ud835\udc32 \ud835\udc01\ud835\udc2b\ud835\udc1e\ud835\udc1e\ud835\udc33\ud835\udc32 \ud835\udc12\ud835\udc1e\ud835\udc2d\ud835\udc2e\ud835\udc29: Plug-and-play, perfect for notebooks and projects.\n\ud83d\udd3b \ud835\udc02\ud835\udc28\ud835\udc27\ud835\udc27\ud835\udc1e\ud835\udc1c\ud835\udc2d\ud835\udc28\ud835\udc2b \ud835\udc02\ud835\udc21\ud835\udc1a\ud835\udc26\ud835\udc29\ud835\udc22\ud835\udc28\ud835\udc27: \ud83d\udd0c Out-of-the-box connectors for Kafka and more (or build your own!).\nIf you're curious to level up your knowledge about streaming pipelines and data engineering \ud83d\udc4a\n\ud835\uddd6\ud835\uddf5\ud835\uddf2\ud835\uddf0\ud835\uddf8 \ud835\uddfc\ud835\ude02\ud835\ude01 \ud835\udc0b\ud835\udc1e\ud835\udc2c\ud835\udc2c\ud835\udc28\ud835\udc27 \ud835\udfd2 \ud835\udc28\ud835\udc1f \ud835\udc03\ud835\udc1e\ud835\udc1c\ud835\udc28\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc0c\ud835\udc0b \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc13\ud835\udc30\ud835\udc22\ud835\udc27 \ud835\udc02\ud835\udc28\ud835\udc2e\ud835\udc2b\ud835\udc2c\ud835\udc1e. It's FREE, and no registration is required\n\u2193\u2193\u2193\n\ud83d\udd17 \ud835\ude13\ud835\ude26\ud835\ude34\ud835\ude34\ud835\ude30\ud835\ude2f 4 -\nhttps://lnkd.in/d32d9HUV\n\ud83d\udd17 \ud835\ude13\ud835\ude13\ud835\ude14 \ud835\ude1b\ud835\ude38\ud835\ude2a\ud835\ude2f \ud835\ude0e\ud835\ude2a\ud835\ude35\ud835\ude29\ud835\ude36\ud835\ude23 \ud835\ude19\ud835\ude26\ud835\ude31\ud835\ude30\ud835\ude34\ud835\ude2a\ud835\ude35\ud835\ude30\ud835\ude33\ud835\ude3a -\nhttps://lnkd.in/dtTeZHN7",
        "image": "https://media.licdn.com/dms/image/D4D22AQHZ5kmZ65qOHw/feedshare-shrink_800/0/1713764708815?e=1717027200&v=beta&t=NEQBRPJ0gugCyPArypF8UWWF0VgBS4e_SnZOmxDPtrU"
    },
    "Post_3": {
        "text": "\ud835\udc3b\ud835\udc4e\ud835\udc63\ud835\udc52 \ud835\udc66\ud835\udc5c\ud835\udc62 \ud835\udc52\ud835\udc63\ud835\udc52\ud835\udc5f \ud835\udc62\ud835\udc60\ud835\udc52\ud835\udc51 \ud835\udc4e\ud835\udc5b \ud835\udc34\ud835\udc3c \ud835\udc61\ud835\udc5c\ud835\udc5c\ud835\udc59 \ud835\udc4e\ud835\udc5b\ud835\udc51 \ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc51 \ud835\udc62\ud835\udc5d \ud835\udc64\ud835\udc56\ud835\udc61\u210e \ud835\udc60\ud835\udc62\ud835\udc5f\ud835\udc5d\ud835\udc5f\ud835\udc56\ud835\udc60\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc59\ud835\udc66 \ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc62\ud835\udc59\ud835\udc61\ud835\udc60?\ud83e\udd14\nCreating a \ud835\udc2e\ud835\udc2c\ud835\udc1e\ud835\udc2b-\ud835\udc1f\ud835\udc2b\ud835\udc22\ud835\udc1e\ud835\udc27\ud835\udc1d\ud835\udc25\ud835\udc32 \ud835\udc1e\ud835\udc31\ud835\udc29\ud835\udc1e\ud835\udc2b\ud835\udc22\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc1e (\ud835\udc14\ud835\udc17) is crucial for non-technical users navigating AI tools.\nThis is where Responsible AI comes in \u2013 ensuring AI systems are intuitive and accessible to everyone.\n\ud83e\udd2f Imagine trying to use complex tech with no instructions \u2013 that's what using AI tools without proper UX can feel like, especially for non-technical users.\n\ud835\udc01\ud835\udc1e\ud835\udc32\ud835\udc28\ud835\udc27\ud835\udc1d \ud835\udc23\ud835\udc2e\ud835\udc2c\ud835\udc2d \ud835\udc1a \ud835\udc1f\ud835\udc2b\ud835\udc22\ud835\udc1e\ud835\udc27\ud835\udc1d\ud835\udc25\ud835\udc32 \ud835\udc22\ud835\udc27\ud835\udc2d\ud835\udc1e\ud835\udc2b\ud835\udc1f\ud835\udc1a\ud835\udc1c\ud835\udc1e, \ud835\udc30\ud835\udc1e \ud835\udc27\ud835\udc1e\ud835\udc1e\ud835\udc1d \ud835\udc2d\ud835\udc28 \ud835\udc20\ud835\udc2e\ud835\udc22\ud835\udc1d\ud835\udc1e \ud835\udc27\ud835\udc28\ud835\udc27-\ud835\udc2d\ud835\udc1e\ud835\udc1c\ud835\udc21\ud835\udc27\ud835\udc22\ud835\udc1c\ud835\udc1a\ud835\udc25 \ud835\udc2e\ud835\udc2c\ud835\udc1e\ud835\udc2b\ud835\udc2c \ud835\udc22\ud835\udc27 \ud835\udc2d\ud835\udc21\ud835\udc1e\ud835\udc22\ud835\udc2b \ud835\udc00\ud835\udc08 \ud835\udc22\ud835\udc27\ud835\udc2d\ud835\udc1e\ud835\udc2b\ud835\udc1a\ud835\udc1c\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c:\n\ud83c\udfaf \ud835\udc0f\ud835\udc2b\ud835\udc28\ud835\udc26\ud835\udc29\ud835\udc2d \ud835\udc0f\ud835\udc28\ud835\udc30\ud835\udc1e\ud835\udc2b-\ud835\udc14\ud835\udc29\ud835\udc2c: Share clear examples of the best ways to interact with the AI tool.\n\ud83c\udfaf \ud835\udc11\ud835\udc1e\ud835\udc2c\ud835\udc2e\ud835\udc25\ud835\udc2d\ud835\udc2c \ud835\udc11\ud835\udc1e\ud835\udc1f\ud835\udc22\ud835\udc27\ud835\udc1e\ud835\udc26\ud835\udc1e\ud835\udc27\ud835\udc2d: Show users how tweaking their inputs gets even better AI outputs.\n\ud83c\udfaf \ud835\udc05\ud835\udc1e\ud835\udc1e\ud835\udc1d\ud835\udc1b\ud835\udc1a\ud835\udc1c\ud835\udc24 \ud835\udc0b\ud835\udc28\ud835\udc28\ud835\udc29: Make it easy for users to provide feedback, actively improving the system.\n\ud835\udc07\ud835\udc1e\ud835\udc2b\ud835\udc1e'\ud835\udc2c \ud835\udc30\ud835\udc21\ud835\udc1e\ud835\udc2b\ud835\udc1e \ud835\udc22\ud835\udc2d \ud835\udc20\ud835\udc1e\ud835\udc2d\ud835\udc2c \ud835\udc1e\ud835\udc2f\ud835\udc1e\ud835\udc27 \ud835\udc26\ud835\udc28\ud835\udc2b\ud835\udc1e \ud835\udc22\ud835\udc27\ud835\udc2d\ud835\udc1e\ud835\udc2b\ud835\udc1e\ud835\udc2c\ud835\udc2d\ud835\udc22\ud835\udc27\ud835\udc20:\n\ud835\udc13\ud835\udc2b\ud835\udc1a\ud835\udc27\ud835\udc2c\ud835\udc29\ud835\udc1a\ud835\udc2b\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc32 \ud835\udc22\ud835\udc2c \ud835\udc24\ud835\udc1e\ud835\udc32: Let people know when they're interacting with an LLM (Large Language Model). This manages expectations and builds trust.\n\ud835\udc12\ud835\udc21\ud835\udc28\ud835\udc30, \ud835\udc1d\ud835\udc28\ud835\udc27'\ud835\udc2d \ud835\udc23\ud835\udc2e\ud835\udc2c\ud835\udc2d \ud835\udc2d\ud835\udc1e\ud835\udc25\ud835\udc25: Can the LLM cite its sources or reveal its thought process? This boosts confidence in the results.\n\ud835\udc06\ud835\udc2e\ud835\udc22\ud835\udc1d\ud835\udc1e, \ud835\udc1b\ud835\udc2e\ud835\udc2d \ud835\udc1d\ud835\udc28\ud835\udc27'\ud835\udc2d \ud835\udc2c\ud835\udc2d\ud835\udc22\ud835\udc1f\ud835\udc25\ud835\udc1e: Design the UI to subtly suggest good inputs, while still leaving room for creativity.\n\ud83e\udd91  \ud835\udc16\ud835\udc21\ud835\udc1a\ud835\udc2d \ud835\udc28\ud835\udc2d\ud835\udc21\ud835\udc1e\ud835\udc2b \ud835\udc14\ud835\udc08/\ud835\udc14\ud835\udc17 \ud835\udc29\ud835\udc2b\ud835\udc22\ud835\udc27\ud835\udc1c\ud835\udc22\ud835\udc29\ud835\udc25\ud835\udc1e\ud835\udc2c \ud835\udc1d\ud835\udc28 \ud835\udc32\ud835\udc28\ud835\udc2e \ud835\udc2d\ud835\udc21\ud835\udc22\ud835\udc27\ud835\udc24 \ud835\udc1a\ud835\udc2b\ud835\udc1e \ud835\udc1c\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc22\ud835\udc1a\ud835\udc25 \ud835\udc1f\ud835\udc28\ud835\udc2b \ud835\udc1b\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc2b\ud835\udc1e\ud835\udc2c\ud835\udc29\ud835\udc28\ud835\udc27\ud835\udc2c\ud835\udc22\ud835\udc1b\ud835\udc25\ud835\udc1e \ud835\udc0b\ud835\udc0b\ud835\udc0c-\ud835\udc29\ud835\udc28\ud835\udc30\ud835\udc1e\ud835\udc2b\ud835\udc1e\ud835\udc1d \ud835\udc1a\ud835\udc29\ud835\udc29\ud835\udc25\ud835\udc22\ud835\udc1c\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc2c?",
        "image": "https://media.licdn.com/dms/image/D4D22AQEO-bTStClzQw/feedshare-shrink_800/0/1712185481852?e=1717027200&v=beta&t=s-l0NFZEqa73c4NwY4LjiF_u4L8hf8IAcDZW_hpiAxk"
    },
    "Post_4": {
        "text": "\ud835\udc08\ud835\udc1f \ud835\udc32\ud835\udc28\ud835\udc2e \ud835\udc30\ud835\udc1a\ud835\udc27\ud835\udc2d \ud835\udc2d\ud835\udc28 \ud835\udc30\ud835\udc2b\ud835\udc22\ud835\udc2d\ud835\udc1e \ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc26\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc29\ud835\udc22\ud835\udc29\ud835\udc1e\ud835\udc25\ud835\udc22\ud835\udc27\ud835\udc1e\ud835\udc2c \ud835\udc25\ud835\udc22\ud835\udc24\ud835\udc1e \ud835\udc1a \ud835\udc0f\ud835\udc11\ud835\udc0e, \ud835\udc1c\ud835\udc21\ud835\udc1e\ud835\udc1c\ud835\udc24 \ud835\udc2d\ud835\udc21\ud835\udc22\ud835\udc2c \ud835\udc28\ud835\udc2e\ud835\udc2d ! \ud83d\udc47\n\ud83d\udddd In a complex ML system, streaming pipelines can be the key to real-time data processing and fine-tuning Large Language Models (LLMs). Here\u2019s a snapshot of what it takes to build a robust streaming pipeline:\n\ud835\udc01\ud835\udc32\ud835\udc2d\ud835\udc1e\ud835\udc30\ud835\udc1a\ud835\udc31 - \ud835\udc0f\ud835\udc32\ud835\udc2d\ud835\udc21\ud835\udc28\ud835\udc27-\ud835\udc1b\ud835\udc1a\ud835\udc2c\ud835\udc1e\ud835\udc1d \ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc26 \ud835\udc29\ud835\udc2b\ud835\udc28\ud835\udc1c\ud835\udc1e\ud835\udc2c\ud835\udc2c\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc26\ud835\udc1e\ud835\udc30\ud835\udc28\ud835\udc2b\ud835\udc24\n\ud83d\udd39Built in Rust \u2699\ufe0f for high performance.\n\ud83d\udd39Python \ud83d\udc0d bindings for easy integration with popular libraries like NumPy and PyTorch.\n\ud83d\udd39Plug-and-play setup: Get started quickly without JVM headaches.\n\ud83d\udd39Broad compatibility: Seamlessly connects with Kafka, and custom connectors.\n\ud835\udc10\ud835\udc1d\ud835\udc2b\ud835\udc1a\ud835\udc27\ud835\udc2d - \ud835\udc1a \ud835\udc21\ud835\udc22\ud835\udc20\ud835\udc21-\ud835\udc29\ud835\udc1e\ud835\udc2b\ud835\udc1f\ud835\udc28\ud835\udc2b\ud835\udc26\ud835\udc1a\ud835\udc27\ud835\udc1c\ud835\udc1e \ud835\udc15\ud835\udc1e\ud835\udc1c\ud835\udc2d\ud835\udc28\ud835\udc2b \ud835\udc03\ud835\udc1a\ud835\udc2d\ud835\udc1a\ud835\udc1b\ud835\udc1a\ud835\udc2c\ud835\udc1e \ud835\udc1d\ud835\udc1e\ud835\udc2c\ud835\udc22\ud835\udc20\ud835\udc27\ud835\udc1e\ud835\udc1d \ud835\udc1f\ud835\udc28\ud835\udc2b \ud835\udc25\ud835\udc1a\ud835\udc2b\ud835\udc20\ud835\udc1e-\ud835\udc2c\ud835\udc1c\ud835\udc1a\ud835\udc25\ud835\udc1e \ud835\udc2f\ud835\udc1e\ud835\udc1c\ud835\udc2d\ud835\udc28\ud835\udc2b \ud835\udc2c\ud835\udc1e\ud835\udc1a\ud835\udc2b\ud835\udc1c\ud835\udc21\ud835\udc1e\ud835\udc2c:\n\ud83d\udd39Real-time vector storage\n\ud83d\udd39Scalability: Efficiently handles large datasets.\n\ud83d\udd39Versatile search capabilities: Includes k-Nearest Neighbors (k-NN) for fast and accurate retrieval.\n\ud83d\udd39Seamless integration: Works smoothly with Bytewax to store and retrieve feature vectors.\nThe pipeline constantly syncs with MongoDB through a \ud835\udc02\ud835\udc03\ud835\udc02 \ud835\udc29\ud835\udc1a\ud835\udc2d\ud835\udc2d\ud835\udc1e\ud835\udc2b\ud835\udc27, ensuring the feature store stays updated with the latest changes. This real-time syncing is crucial for reliable results in LLM fine-tuning and RAG applications.\nIf you're curious to level up your knowledge about streaming pipelines and data engineering \ud83d\udc4a\n\ud835\uddd6\ud835\uddf5\ud835\uddf2\ud835\uddf0\ud835\uddf8 \ud835\uddfc\ud835\ude02\ud835\ude01 \ud835\udc0b\ud835\udc1e\ud835\udc2c\ud835\udc2c\ud835\udc28\ud835\udc27 \ud835\udfd2 \ud835\udc28\ud835\udc1f \ud835\udc03\ud835\udc1e\ud835\udc1c\ud835\udc28\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc0c\ud835\udc0b \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc13\ud835\udc30\ud835\udc22\ud835\udc27 \ud835\udc02\ud835\udc28\ud835\udc2e\ud835\udc2b\ud835\udc2c\ud835\udc1e. It's FREE, and no registration is required\n\u2193\u2193\u2193\n\ud83d\udd17 \ud835\ude13\ud835\ude26\ud835\ude34\ud835\ude34\ud835\ude30\ud835\ude2f 4 -\nhttps://lnkd.in/d32d9HUV\n\ud835\ude1a\ud835\ude35\ud835\ude33\ud835\ude26\ud835\ude22\ud835\ude2e\ud835\ude2a\ud835\ude2f\ud835\ude28 \ud835\ude17\ud835\ude2a\ud835\ude31\ud835\ude26\ud835\ude2d\ud835\ude2a\ud835\ude2f\ud835\ude26\ud835\ude34:\nhttps://lnkd.in/dwV8sis2\n\ud835\ude1d\ud835\ude26\ud835\ude24\ud835\ude35\ud835\ude30\ud835\ude33 \ud835\ude0b\ud835\ude09:\nhttps://lnkd.in/d9DV7UaJ",
        "image": "https://media.licdn.com/dms/image/D4D22AQH8hT_p2JuEZg/feedshare-shrink_800/0/1712044154177?e=1717027200&v=beta&t=ZLm1QwwjE5CzyPu2t9pjL9UVK2Li3INSGDKiEYYelPs"
    },
    "Post_5": {
        "text": "\ud835\udc02\ud835\udc2e\ud835\udc2d\ud835\udc2d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc13\ud835\udc21\ud835\udc2b\ud835\udc28\ud835\udc2e\ud835\udc20\ud835\udc21 \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc00\ud835\udc08 \ud835\udc07\ud835\udc32\ud835\udc29\ud835\udc1e: \ud835\udc08\ud835\udc2d\u2019\ud835\udc2c \ud835\udc13\ud835\udc22\ud835\udc26\ud835\udc1e \ud835\udc2d\ud835\udc28 \ud835\udc13\ud835\udc1a\ud835\udc25\ud835\udc24 \ud835\udc03\ud835\udc1a\ud835\udc2d\ud835\udc1a \ud835\udc10\ud835\udc2e\ud835\udc1a\ud835\udc25\ud835\udc22\ud835\udc2d\ud835\udc32 \ud83e\udd10\nThere's a lot of excitement about what AI can do, but there\u2019s not enough talk about what it takes to make AI work properly.\nThe truth? Good AI needs good data. Without it, even the smartest AI falls short. \ud83d\udc47\nCompanies want AI for faster decisions and better processes.\nHowever, executives and directors don't want to listen to data engineers who warn them about the risks of rushing into AI without solid data.\nBut can they trust what AI tells them if they\u2019re unsure about their data?\nWhen data gets neglected, doubts creep in. And nobody should make big choices on shaky ground. \ud83d\ude44\nThe hype of Generative AI is loud, but let\u2019s not get carried away.\nLet's focus on getting our data right. Because when we trust our data, we can trust the AI that relies on it.",
        "image": "https://media.licdn.com/dms/image/D4D22AQFMEvuBSvOAVA/feedshare-shrink_800/0/1711873708088?e=1717027200&v=beta&t=GlnBmlicE1Sb-pRDR8r79CSM_UOOMT74CKFISBixiTg"
    },
    "Post_6": {
        "text": "\ud83d\udc68\u200d\ud83d\udd2c \ud835\udc01\ud835\udc1e\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc1a\ud835\udc27 \ud835\udc00\ud835\udc08 \ud835\udc1e\ud835\udc27\ud835\udc20\ud835\udc22\ud835\udc27\ud835\udc1e\ud835\udc1e\ud835\udc2b \ud835\udc26\ud835\udc1e\ud835\udc1a\ud835\udc27\ud835\udc2c \ud835\udc30\ud835\udc28\ud835\udc2b\ud835\udc24\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc30\ud835\udc22\ud835\udc2d\ud835\udc21 \ud835\udc1c\ud835\udc28\ud835\udc28\ud835\udc25 \ud835\udc2d\ud835\udc1e\ud835\udc1c\ud835\udc21 \ud835\udc1a\ud835\udc27\ud835\udc1d \ud835\udc2c\ud835\udc26\ud835\udc1a\ud835\udc2b\ud835\udc2d \ud835\udc1a\ud835\udc25\ud835\udc20\ud835\udc28\ud835\udc2b\ud835\udc22\ud835\udc2d\ud835\udc21\ud835\udc26\ud835\udc2c \ud835\udc1d\ud835\udc1a\ud835\udc22\ud835\udc25\ud835\udc32.\n\ud83d\udc4a But that's not all there is to it. I've also learned that knowing how to use tools like\nPulumi\nand Terraform is super important.\n\ud83d\ude84 In a world where everything moves at lightning speed, the ability to quickly spin up \ud835\udc0c\ud835\udc15\ud835\udc0f\ud835\udc2c \ud835\udc2d\ud835\udc21\ud835\udc1a\ud835\udc2d \ud835\udc2b\ud835\udc2e\ud835\udc27 \ud835\udc28\ud835\udc27 \ud835\udc26\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc26\ud835\udc1a\ud835\udc25 \ud835\udc1c\ud835\udc25\ud835\udc28\ud835\udc2e\ud835\udc1d \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e is crucial. It's about swiftly simulating reality to test our ideas in real-world conditions.\n\ud835\udc08 \ud835\udc2b\ud835\udc1e\ud835\udc1c\ud835\udc1e\ud835\udc27\ud835\udc2d\ud835\udc25\ud835\udc32 \ud835\udc26\ud835\udc22\ud835\udc20\ud835\udc2b\ud835\udc1a\ud835\udc2d\ud835\udc1e\ud835\udc1d \ud835\udc26\ud835\udc32 \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc1c\ud835\udc28\ud835\udc1d\ud835\udc1e \ud835\udc1f\ud835\udc2b\ud835\udc28\ud835\udc26 \ud835\udc13\ud835\udc1e\ud835\udc2b\ud835\udc2b\ud835\udc1a\ud835\udc1f\ud835\udc28\ud835\udc2b\ud835\udc26 \ud835\udc2d\ud835\udc28\nPulumi\n, \ud835\udc1a\ud835\udc27\ud835\udc1d \ud835\udc21\ud835\udc1e\ud835\udc2b\ud835\udc1e'\ud835\udc2c \ud835\udc30\ud835\udc21\ud835\udc32 \ud835\udc22\ud835\udc2d \ud835\udc26\ud835\udc1a\ud835\udc1d\ud835\udc1e \ud835\udc1a \ud835\udc1b\ud835\udc22\ud835\udc20 \ud835\udc1d\ud835\udc22\ud835\udc1f\ud835\udc1f\ud835\udc1e\ud835\udc2b\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc1e!\nBoth Terraform and Pulumi are fantastic IaC tools, but for my projects, Pulumi offered some key advantages: \ud83d\udc47\n\ud835\udc0b\ud835\udc1a\ud835\udc27\ud835\udc20\ud835\udc2e\ud835\udc1a\ud835\udc20\ud835\udc1e \ud835\udc05\ud835\udc1a\ud835\udc26\ud835\udc22\ud835\udc25\ud835\udc22\ud835\udc1a\ud835\udc2b\ud835\udc22\ud835\udc2d\ud835\udc32: \ud835\udc48\ud835\udc5b\ud835\udc59\ud835\udc56\ud835\udc58\ud835\udc52 \ud835\udc47\ud835\udc52\ud835\udc5f\ud835\udc5f\ud835\udc4e\ud835\udc53\ud835\udc5c\ud835\udc5f\ud835\udc5a, \ud835\udc64\u210e\ud835\udc56\ud835\udc50\u210e \ud835\udc62\ud835\udc60\ud835\udc52\ud835\udc60 \ud835\udc3b\ud835\udc4e\ud835\udc60\u210e\ud835\udc56\ud835\udc36\ud835\udc5c\ud835\udc5f\ud835\udc5d \ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc53\ud835\udc56\ud835\udc54\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b \ud835\udc3f\ud835\udc4e\ud835\udc5b\ud835\udc54\ud835\udc62\ud835\udc4e\ud835\udc54\ud835\udc52 (\ud835\udc3b\ud835\udc36\ud835\udc3f), \ud835\udc43\ud835\udc62\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc56 \ud835\udc4e\ud835\udc59\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc60 \ud835\udc66\ud835\udc5c\ud835\udc62 \ud835\udc61\ud835\udc5c \ud835\udc51\ud835\udc52\ud835\udc53\ud835\udc56\ud835\udc5b\ud835\udc52 \ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc5f\ud835\udc4e\ud835\udc60\ud835\udc61\ud835\udc5f\ud835\udc62\ud835\udc50\ud835\udc61\ud835\udc62\ud835\udc5f\ud835\udc52 \ud835\udc62\ud835\udc60\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc54\ud835\udc52\ud835\udc5b\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc59-\ud835\udc5d\ud835\udc62\ud835\udc5f\ud835\udc5d\ud835\udc5c\ud835\udc60\ud835\udc52 \ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc54\ud835\udc5f\ud835\udc4e\ud835\udc5a\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc59\ud835\udc4e\ud835\udc5b\ud835\udc54\ud835\udc62\ud835\udc4e\ud835\udc54\ud835\udc52\ud835\udc60 \ud835\udc60\ud835\udc62\ud835\udc50\u210e \ud835\udc4e\ud835\udc60 \ud835\udc43\ud835\udc66\ud835\udc61\u210e\ud835\udc5c\ud835\udc5b, \ud835\udc3d\ud835\udc4e\ud835\udc63\ud835\udc4e\ud835\udc46\ud835\udc50\ud835\udc5f\ud835\udc56\ud835\udc5d\ud835\udc61, \ud835\udc47\ud835\udc66\ud835\udc5d\ud835\udc52\ud835\udc46\ud835\udc50\ud835\udc5f\ud835\udc56\ud835\udc5d\ud835\udc61, \ud835\udc4e\ud835\udc5b\ud835\udc51 \ud835\udc3a\ud835\udc5c.\n\ud835\udc11\ud835\udc1e\ud835\udc2e\ud835\udc2c\ud835\udc1a\ud835\udc1b\ud835\udc25\ud835\udc1e \ud835\udc02\ud835\udc28\ud835\udc26\ud835\udc29\ud835\udc28\ud835\udc27\ud835\udc1e\ud835\udc27\ud835\udc2d\ud835\udc2c: \ud835\udc43\ud835\udc62\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc56 \ud835\udc52\ud835\udc5b\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc54\ud835\udc52\ud835\udc60 \ud835\udc61\u210e\ud835\udc52 \ud835\udc62\ud835\udc60\ud835\udc52 \ud835\udc5c\ud835\udc53 \ud835\udc50\ud835\udc5c\ud835\udc5a\ud835\udc5d\ud835\udc5c\ud835\udc5b\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc60, \ud835\udc64\u210e\ud835\udc56\ud835\udc50\u210e \ud835\udc4e\ud835\udc5f\ud835\udc52 \u210e\ud835\udc56\ud835\udc54\u210e\ud835\udc52\ud835\udc5f-\ud835\udc59\ud835\udc52\ud835\udc63\ud835\udc52\ud835\udc59 \ud835\udc4e\ud835\udc4f\ud835\udc60\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc50\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc60 \ud835\udc61\u210e\ud835\udc4e\ud835\udc61 \ud835\udc5d\ud835\udc4e\ud835\udc50\ud835\udc58\ud835\udc4e\ud835\udc54\ud835\udc52 \ud835\udc62\ud835\udc5d \ud835\udc50\ud835\udc5c\ud835\udc5a\ud835\udc5a\ud835\udc5c\ud835\udc5b\ud835\udc59\ud835\udc66 \ud835\udc62\ud835\udc60\ud835\udc52\ud835\udc51 \ud835\udc5d\ud835\udc4e\ud835\udc61\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc5b\ud835\udc60 \ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc5c \ud835\udc5f\ud835\udc52\ud835\udc62\ud835\udc60\ud835\udc4e\ud835\udc4f\ud835\udc59\ud835\udc52 \ud835\udc5a\ud835\udc5c\ud835\udc51\ud835\udc62\ud835\udc59\ud835\udc52\ud835\udc60. \ud835\udc47\u210e\ud835\udc56\ud835\udc60 \ud835\udc50\ud835\udc4e\ud835\udc5b \ud835\udc4f\ud835\udc52 \ud835\udc52\ud835\udc60\ud835\udc5d\ud835\udc52\ud835\udc50\ud835\udc56\ud835\udc4e\ud835\udc59\ud835\udc59\ud835\udc66 \ud835\udc62\ud835\udc60\ud835\udc52\ud835\udc53\ud835\udc62\ud835\udc59 \ud835\udc64\u210e\ud835\udc52\ud835\udc5b \ud835\udc34\ud835\udc3c \ud835\udc52\ud835\udc5b\ud835\udc54\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc52\ud835\udc5f\ud835\udc60 \ud835\udc5b\ud835\udc52\ud835\udc52\ud835\udc51 \ud835\udc61\ud835\udc5c \ud835\udc5f\ud835\udc52\ud835\udc5d\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61\ud835\udc52 \ud835\udc60\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc59\ud835\udc4e\ud835\udc5f \ud835\udc52\ud835\udc5b\ud835\udc63\ud835\udc56\ud835\udc5f\ud835\udc5c\ud835\udc5b\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc60 \ud835\udc5e\ud835\udc62\ud835\udc56\ud835\udc50\ud835\udc58\ud835\udc59\ud835\udc66 \ud835\udc53\ud835\udc5c\ud835\udc5f \ud835\udc51\ud835\udc56\ud835\udc53\ud835\udc53\ud835\udc52\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61 \ud835\udc40\ud835\udc49\ud835\udc43\ud835\udc60.\n\ud835\udc12\ud835\udc2d\ud835\udc1a\ud835\udc2d\ud835\udc1e \ud835\udc0c\ud835\udc1a\ud835\udc27\ud835\udc1a\ud835\udc20\ud835\udc1e\ud835\udc26\ud835\udc1e\ud835\udc27\ud835\udc2d: \ud835\udc43\ud835\udc62\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc56 \ud835\udc60\ud835\udc56\ud835\udc5a\ud835\udc5d\ud835\udc59\ud835\udc56\ud835\udc53\ud835\udc56\ud835\udc52\ud835\udc60 \ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52 \ud835\udc5a\ud835\udc4e\ud835\udc5b\ud835\udc4e\ud835\udc54\ud835\udc52\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61 \ud835\udc4f\ud835\udc66 \ud835\udc4e\ud835\udc62\ud835\udc61\ud835\udc5c\ud835\udc5a\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc59\ud835\udc66 \u210e\ud835\udc4e\ud835\udc5b\ud835\udc51\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52 \ud835\udc53\ud835\udc56\ud835\udc59\ud835\udc52\ud835\udc60 \ud835\udc4e\ud835\udc5b\ud835\udc51 \ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc63\ud835\udc56\ud835\udc51\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc53\ud835\udc52\ud835\udc4e\ud835\udc61\ud835\udc62\ud835\udc5f\ud835\udc52\ud835\udc60 \ud835\udc59\ud835\udc56\ud835\udc58\ud835\udc52 \ud835\udc4f\ud835\udc62\ud835\udc56\ud835\udc59\ud835\udc61-\ud835\udc56\ud835\udc5b \ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52 \ud835\udc59\ud835\udc5c\ud835\udc50\ud835\udc58\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc4e\ud835\udc5b\ud835\udc51 \ud835\udc52\ud835\udc5b\ud835\udc50\ud835\udc5f\ud835\udc66\ud835\udc5d\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b. \ud835\udc47\u210e\ud835\udc56\ud835\udc60 \ud835\udc5a\ud835\udc52\ud835\udc4e\ud835\udc5b\ud835\udc60 \ud835\udc59\ud835\udc52\ud835\udc60\ud835\udc60 \ud835\udc60\ud835\udc52\ud835\udc61\ud835\udc62\ud835\udc5d \ud835\udc4e\ud835\udc5b\ud835\udc51 \ud835\udc5a\ud835\udc4e\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5b\ud835\udc4e\ud835\udc5b\ud835\udc50\ud835\udc52 \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc58, \ud835\udc4e\ud835\udc59\ud835\udc59\ud835\udc5c\ud835\udc64\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc5a\ud835\udc52 \ud835\udc61\ud835\udc5c \ud835\udc53\ud835\udc5c\ud835\udc50\ud835\udc62\ud835\udc60 \ud835\udc5a\ud835\udc5c\ud835\udc5f\ud835\udc52 \ud835\udc5c\ud835\udc5b \ud835\udc4f\ud835\udc62\ud835\udc56\ud835\udc59\ud835\udc51\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc34\ud835\udc3c \ud835\udc50\ud835\udc5c\ud835\udc51\ud835\udc52 \ud835\udc4e\ud835\udc5b\ud835\udc51 \ud835\udc59\ud835\udc52\ud835\udc60\ud835\udc60 \ud835\udc5c\ud835\udc5b \ud835\udc61\u210e\ud835\udc52 \ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc5f\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc50\ud835\udc56\ud835\udc52\ud835\udc60 \ud835\udc5c\ud835\udc53 \ud835\udc56\ud835\udc5b\ud835\udc53\ud835\udc5f\ud835\udc4e\ud835\udc60\ud835\udc61\ud835\udc5f\ud835\udc62\ud835\udc50\ud835\udc61\ud835\udc62\ud835\udc5f\ud835\udc52.\nIn the world of generative AI, it's more important than ever for us AI engineers to not just focus on AI itself, but also on other key software engineering skills.\nUnderstanding tools like Pulumi or Terraform helps us build better, smarter AI applications.\nAs the tech grows, so must our skills \u2013 it's all about staying versatile and ready for anything!",
        "image": "https://media.licdn.com/dms/image/D4D22AQEfUJlgYkwgqg/feedshare-shrink_800/0/1711613637296?e=1717027200&v=beta&t=jiiSRmNce2aizzen18mxKeRp8BHc_q9n-dM5MwZjvlU"
    },
    "Post_7": {
        "text": "\ud835\udc02\ud835\udc21\ud835\udc1a\ud835\udc2d\ud835\udc06\ud835\udc0f\ud835\udc13 \ud835\udc22\ud835\udc2c \ud835\udc1e\ud835\udc2f\ud835\udc1e\ud835\udc2b\ud835\udc32\ud835\udc30\ud835\udc21\ud835\udc1e\ud835\udc2b\ud835\udc1e...\ud83d\ude44\nI bet all of you, including me, use ChatGPT to help us write content or brainstorm new ideas.\n\ud835\udc00 \ud835\udc2c\ud835\udc2d\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc2c\ud835\udc2d\ud835\udc22\ud835\udc1c \ud835\udc1f\ud835\udc2b\ud835\udc28\ud835\udc26 \ud835\udc07\ud835\udc2e\ud835\udc1b\ud835\udc2c\ud835\udc29\ud835\udc28\ud835\udc2d \ud835\udc2d\ud835\udc1e\ud835\udc25\ud835\udc25\ud835\udc2c \ud835\udc2e\ud835\udc2c \ud835\udc2d\ud835\udc21\ud835\udc1a\ud835\udc2d:\n\ud83d\udcc8 73% of marketers use AI to some degree\n\ud83d\udcc831% of non-users plan to adopt within a year\n\ud83d\udcc846% will embrace AI within two years\nWhat does this mean?\nIdentical content from one user to another means the brand identity will be very affected.\n\ud835\udc13\ud835\udc21\ud835\udc1e \ud835\udc2c\ud835\udc28\ud835\udc25\ud835\udc2e\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27?\n\ud835\udc01\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d your \ud835\udddf\ud835\udddf\ud835\udde0 \ud835\ude01\ud835\ude04\ud835\uddf6\ud835\uddfb for \ud835\uddf4\ud835\uddf2\ud835\uddfb\ud835\uddf2\ud835\uddff\ud835\uddee\ud835\ude01\ud835\uddf6\ud835\uddfb\ud835\uddf4 posts or articles \ud835\ude02\ud835\ude00\ud835\uddf6\ud835\uddfb\ud835\uddf4 \ud835\ude06\ud835\uddfc\ud835\ude02\ud835\uddff \ud835\ude03\ud835\uddfc\ud835\uddf6\ud835\uddf0\ud835\uddf2 \u2193\nThis requires a system fine-tuned with your content, using a vector DB to stick to factual writing and avoid off-track results.\nFrom an \ud835\udc1e\ud835\udc27\ud835\udc20\ud835\udc22\ud835\udc27\ud835\udc1e\ud835\udc1e\ud835\udc2b\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc29\ud835\udc28\ud835\udc22\ud835\udc27\ud835\udc2d \ud835\udc28\ud835\udc1f \ud835\udc2f\ud835\udc22\ud835\udc1e\ud835\udc30 here are the main steps you need to build this:\n\ud83c\udfaf Data Collection: Aggregate your digital footprint from platforms like Medium and LinkedIn, process and store it in MongoDB.\n\ud83c\udfafChange Detection: Use CDC to monitor\nMongoDB\nupdates, channeling these changes to a\nRabbitMQ\nqueue.\n\ud83c\udfafFeature Pipeline: A\nBytewax\npipeline listens to the queue, cleans, and structures the data, supported by\nSuperlinked\n.\n\ud83c\udfafData Storage: Store processed data in a\nQdrant\nvector DB.\n\ud83c\udfafTraining: Create your dataset from cleaned data and fine-tune with\nQwak\na Mistral LLM using QLoRA, tracking experiments with\nComet\n.\n\ud83c\udfafEvaluation and Deployment: Choose the best LLM model based on Comet's evaluation, then deploy it for inference via a REST API.\n\ud83d\udc4a In the following articles and posts, the & Decoding ML team  will show you all the steps to build the LLM Twin, which learns your \ud835\udc29\ud835\udc2c\ud835\udc32\ud835\udc1c\ud835\udc21\ud835\udc28\ud835\udc25\ud835\udc28\ud835\udc20\ud835\udc22\ud835\udc1c\ud835\udc1a\ud835\udc25 \ud835\udc1a\ud835\udc27\ud835\udc1d \ud835\udc2d\ud835\udc1e\ud835\udc1c\ud835\udc21\ud835\udc27\ud835\udc22\ud835\udc1c\ud835\udc1a\ud835\udc25 \ud835\udc29\ud835\udc2b\ud835\udc28\ud835\udc1f\ud835\udc22\ud835\udc25\ud835\udc1e by providing unique and valuable content.\n\ud835\uddd6\ud835\uddf5\ud835\uddf2\ud835\uddf0\ud835\uddf8 \ud835\uddf6\ud835\ude01 \ud835\uddfc\ud835\ude02\ud835\ude01 \ud835\uddfc\ud835\uddfb \ud835\uddda\ud835\uddf6\ud835\ude01\ud835\udddb\ud835\ude02\ud835\uddef \ud835\uddee\ud835\uddfb\ud835\uddf1 \ud835\ude00\ud835\ude02\ud835\uddfd\ud835\uddfd\ud835\uddfc\ud835\uddff\ud835\ude01 \ud835\ude02\ud835\ude00 \ud835\ude04\ud835\uddf6\ud835\ude01\ud835\uddf5 \ud835\uddee \u2b50\ufe0f\n\u2193\u2193\u2193\n\ud83d\udd17 \ud835\ude13\ud835\ude13\ud835\ude14 \ud835\ude1b\ud835\ude38\ud835\ude2a\ud835\ude2f \ud835\ude0a\ud835\ude30\ud835\ude36\ud835\ude33\ud835\ude34\ud835\ude26: \ud835\ude09\ud835\ude36\ud835\ude2a\ud835\ude2d\ud835\ude25\ud835\ude2a\ud835\ude2f\ud835\ude28 \ud835\ude20\ud835\ude30\ud835\ude36\ud835\ude33 \ud835\ude17\ud835\ude33\ud835\ude30\ud835\ude25\ud835\ude36\ud835\ude24\ud835\ude35\ud835\ude2a\ud835\ude30\ud835\ude2f-\ud835\ude19\ud835\ude26\ud835\ude22\ud835\ude25\ud835\ude3a \ud835\ude08\ud835\ude10 \ud835\ude19\ud835\ude26\ud835\ude31\ud835\ude2d\ud835\ude2a\ud835\ude24\ud835\ude22 GitHub Repository:\nhttps://lnkd.in/dY6_Hi9r\nAlso, if you want to learn more about the course check this medium article.\n\u2193\u2193\u2193\n\ud83d\udd17\nhttps://lnkd.in/dSHJb8yz",
        "image": "https://media.licdn.com/dms/image/D4D22AQEe2KktNRJaEg/feedshare-shrink_800/0/1710841116512?e=1717027200&v=beta&t=jfpn_IpcvW1Mh4TDt_-2a9nv9cdKzBYdoIgQJULE_4w"
    },
    "Post_8": {
        "text": "\ud835\udc05\ud835\udc22\ud835\udc27\ud835\udc1d \ud835\udc32\ud835\udc28\ud835\udc2e\ud835\udc2b \ud835\udc16\ud835\udc07\ud835\udc18 \ud835\udc1a\ud835\udc27\ud835\udc1d \ud835\udc1c\ud835\udc28\ud835\udc27\ud835\udc2d\ud835\udc22\ud835\udc27\ud835\udc2e\ud835\udc1e \ud835\udc2d\ud835\udc28 \ud835\udc1b\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d \ud835\udc1a\ud835\udc27\ud835\udc1d \ud835\udc1f\ud835\udc28\ud835\udc25\ud835\udc25\ud835\udc28\ud835\udc30 \ud835\udc32\ud835\udc28\ud835\udc2e \ud835\udc1d\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc26\ud835\udc2c.\nThis was the advice I gave at a meetup organized by\n\u2728 Andrei Cosmin Munteanu\nwithin the InnovationLabs incubator.\n\ud83e\udd8b The energy of young entrepreneurs is genuinely inspiring!\nThey're coming with ideas and a passion to make a difference.\n\ud83d\udcb9 However, during the discussion, I noticed a trend - many are drawn to the startup world because it's seen as \"sexy\" or the new \"cool.\"\nWhile chasing trends can be exciting, a strong foundation built on a clear \"why\" is crucial for long-term success.\n\ud83d\ude82 Your \"why\" is the driving force that fuels your motivation, keeps you resilient through challenges and allows you to connect with your target audience truly.\nSo, for future young entrepreneurs,  \ud835\udc2b\ud835\udc1e\ud835\udc26\ud835\udc1e\ud835\udc26\ud835\udc1b\ud835\udc1e\ud835\udc2b \ud835\udc2d\ud835\udc21\ud835\udc1a\ud835\udc2d \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc2b\ud835\udc28\ud835\udc1a\ud835\udc1d \ud835\udc2d\ud835\udc28 \ud835\udc1b\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc2c\ud835\udc28\ud835\udc26\ud835\udc1e\ud835\udc2d\ud835\udc21\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc20\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc2d \ud835\udc22\ud835\udc2c \ud835\udc2b\ud835\udc1a\ud835\udc2b\ud835\udc1e\ud835\udc25\ud835\udc32 \ud835\udc2c\ud835\udc26\ud835\udc28\ud835\udc28\ud835\udc2d\ud835\udc21.\nResilience and passion are the fuel that will keep you going when faced with challenges.\nPS: Honestly, these are also important reminders for me. \ud83c\udf1d\nThanks,\n\u2728 Andrei Cosmin Munteanu\n,\nRadu Ticiu\nand\nOvidiu Stegari\nfor helping the community by sharing your experiences.",
        "image": "https://media.licdn.com/dms/image/D4D22AQEQNA1B-DWYww/feedshare-shrink_800/0/1710239351908?e=1717027200&v=beta&t=79-gxv_O_1DW5rXKBNa2cEBSOcAKX5EhoCvEZaMbji0"
    },
    "Post_9": {
        "text": "\ud835\udc13\ud835\udc21\ud835\udc22\ud835\udc2c \ud835\udc22\ud835\udc2c \ud835\udc21\ud835\udc28\ud835\udc30 \ud835\udc32\ud835\udc28\ud835\udc2e \ud835\udc1c\ud835\udc1a\ud835\udc27 \ud835\udc00\ud835\udc02\ud835\udc13\ud835\udc14\ud835\udc00\ud835\udc0b\ud835\udc0b\ud835\udc18 \ud835\udc26\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc1e\ud835\udc2b \ud835\udc1d\ud835\udc1a\ud835\udc2d\ud835\udc1a \ud835\udc29\ud835\udc22\ud835\udc29\ud835\udc1e\ud835\udc25\ud835\udc22\ud835\udc27\ud835\udc1e \ud835\udc1e\ud835\udc27\ud835\udc20\ud835\udc22\ud835\udc27\ud835\udc1e\ud835\udc1e\ud835\udc2b\ud835\udc22\ud835\udc27\ud835\udc20. \ud83e\udef5\nHello everybody! \ud83d\udd90\nWelcome to the 2nd lesson of our \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc13\ud835\udc30\ud835\udc22\ud835\udc27: \ud835\udc01\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc18\ud835\udc28\ud835\udc2e\ud835\udc2b \ud835\udc0f\ud835\udc2b\ud835\udc28\ud835\udc1d\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27-\ud835\udc11\ud835\udc1e\ud835\udc1a\ud835\udc1d\ud835\udc32 \ud835\udc00\ud835\udc08 \ud835\udc11\ud835\udc1e\ud835\udc29\ud835\udc25\ud835\udc22\ud835\udc1c\ud835\udc1a - \ud835\udc05\ud835\udc11\ud835\udc04\ud835\udc04 \ud835\udc02\ud835\udc28\ud835\udc2e\ud835\udc2b\ud835\udc2c\ud835\udc1e.\nAccess it here: \ud83d\udd17\nhttps://lnkd.in/dQjJFcCU\nWe are kicking off this lesson by showing you how to build a data pipeline by respecting the best\nhashtag\n#\nMLOps\npractices.\n\ud83c\udf10 \ud835\udc03\ud835\udc1a\ud835\udc2d\ud835\udc1a is the engine of any ML model.\nIf we don\u2019t give enough importance to it, we cannot be in control of the final output.\nThat is why I emphasize this first and very important step.\nWhat's in store for today's lesson \u2753\n\ud83d\udd3b Data collection process -> Medium, Github, Substack & Linkedin crawlers\n\ud83d\udd3b ETL pipelines -> data is cleaned and normalized\n\ud83d\udd3b ODM (Object Document Mapping ) -> a technique that maps between an object model in an application and a document database\n\ud83d\udd3b NoSQL Database (\nMongoDB\n) & CDC (Change Data Capture) pattern\n- Tracks data changes log them, and queues messages for real-time system updates\n- The clean data is stored in a NoSQL database\n\ud83d\udd3b Feature Pipeline\n- A streaming ingestion pipeline is part of the feature pipeline that processes -Articles, Posts, and Code.\n- Tools like\nBytewax\nand\nSuperlinked\nare used, likely for further data processing and transformation.\n- This processed data is then queued in\nRabbitMQ\n, a message broker that helps in asynchronous processing and communication between different services.\nThe LLM Twin Challenge STARTS NOW \u2757 for the next 9 weeks you are embarking on a hands-on experience that will bring another skill to your portfolio: deploying an end-to-end production-grade LLM system.\nIf you want to learn more about the technologies used in this lesson check out:\n\ud83c\udfaf \ud835\udc49\ud835\udc52\ud835\udc50\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc37\ud835\udc4f:\nhttps://lnkd.in/dQ6kwC_Z\n\ud83c\udfaf \ud835\udc46\ud835\udc61\ud835\udc5f\ud835\udc52\ud835\udc4e\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc43\ud835\udc56\ud835\udc5d\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52:\nhttps://lnkd.in/dsJw6gBW\n\ud83c\udfaf \ud835\udc40\ud835\udc52\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc44\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52:\nhttps://www.rabbitmq.com/\n\ud83e\uddd9\u200d\u2642\ufe0f Steal our code:\n\ud83d\udd17\nhttps://lnkd.in/dtTeZHN7",
        "image": "https://media.licdn.com/dms/image/D4D22AQFUyOLHEkNaKg/feedshare-shrink_800/0/1706667297497?e=1717027200&v=beta&t=_1l3QDVGoMVjhM4Gvl9QDx8HnHlybC-prS_2OKyuO5w"
    },
    "Post_10": {
        "text": "\ud835\udc13\ud835\udc21\ud835\udc22\ud835\udc2c \ud835\udc22\ud835\udc2c \ud835\udc21\ud835\udc28\ud835\udc30 \ud835\udc32\ud835\udc28\ud835\udc2e \ud835\udc2c\ud835\udc21\ud835\udc28\ud835\udc2e\ud835\udc25\ud835\udc1d \ud835\udc1b\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d \ud835\udc32\ud835\udc28\ud835\udc2e\ud835\udc2b \ud835\udc1d\ud835\udc1a\ud835\udc2d\ud835\udc1a \ud835\udc29\ud835\udc22\ud835\udc29\ud835\udc1e\ud835\udc25\ud835\udc22\ud835\udc27\ud835\udc1e \ud835\udc22\ud835\udc27 \ud835\udc32\ud835\udc28\ud835\udc2e\ud835\udc2b \ud835\udc0c\ud835\udc0b \ud835\udc29\ud835\udc2b\ud835\udc28\ud835\udc23\ud835\udc1e\ud835\udc1c\ud835\udc2d\ud835\udc2c. \ud83d\udc47\n\ud83d\udcd1 Data is the lifeblood of any successful AI project, and a well-engineered data pipeline is the key to harnessing its power.\nYou may ask: \u201c\ud835\udc0e\ud835\udc24\ud835\udc1a\ud835\udc32 \ud835\udc00\ud835\udc25\ud835\udc1e\ud835\udc31, \ud835\udc30\ud835\udc21\ud835\udc1a\ud835\udc2d \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc21\ud835\udc1e\ud835\udc1c\ud835\udc24 \ud835\udc22\ud835\udc2c \ud835\udc1a \ud835\udc1d\ud835\udc1a\ud835\udc2d\ud835\udc1a \ud835\udc29\ud835\udc22\ud835\udc29\ud835\udc1e\ud835\udc25\ud835\udc22\ud835\udc27\ud835\udc1e, \ud835\udc1a\ud835\udc27\ud835\udc1d \ud835\udc30\ud835\udc21\ud835\udc32 \ud835\udc22\ud835\udc2c \ud835\udc22\ud835\udc2d \ud835\udc2c\ud835\udc28 \ud835\udc1c\ud835\udc2b\ud835\udc22\ud835\udc2d\ud835\udc22\ud835\udc1c\ud835\udc1a\ud835\udc25?\u201d\nHear me out! A data pipeline is a series of automated steps that guide\nhashtag\n#\ndata\non a purpose.\nImagine this automated system acts as the engine, seamlessly moving data through various stages and transforming it from raw form into actionable insights.\n\ud83d\udca1 \ud835\udc01\ud835\udc2e\ud835\udc2d \ud835\udc21\ud835\udc28\ud835\udc30 \ud835\udc1c\ud835\udc1a\ud835\udc27 \ud835\udc30\ud835\udc1e \ud835\udc2d\ud835\udc2b\ud835\udc1a\ud835\udc27\ud835\udc2c\ud835\udc1f\ud835\udc28\ud835\udc2b\ud835\udc26 \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc2b\ud835\udc1a\ud835\udc30 \ud835\udc1d\ud835\udc1a\ud835\udc2d\ud835\udc1a \ud835\udc22\ud835\udc27\ud835\udc2d\ud835\udc28 \ud835\udc1a\ud835\udc1c\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc1a\ud835\udc1b\ud835\udc25\ud835\udc1e \ud835\udc22\ud835\udc27\ud835\udc2c\ud835\udc22\ud835\udc20\ud835\udc21\ud835\udc2d\ud835\udc2c?\nIn \ud835\udc3f\ud835\udc52\ud835\udc60\ud835\udc60\ud835\udc5c\ud835\udc5b 2 of the \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc13\ud835\udc30\ud835\udc22\ud835\udc27 \ud835\udc05\ud835\udc2b\ud835\udc1e\ud835\udc1e \ud835\udc1c\ud835\udc28\ud835\udc2e\ud835\udc2b\ud835\udc2c\ud835\udc1e by Decoding ML we are focusing on how to build an end to end data pipeline by building:\n\ud83d\udd3b Data collection process -> Medium, Github, Substack & Linkedin crawlers\n\ud83d\udd3b ETL pipelines -> data is cleaned and normalized\n\ud83d\udd3b ODM (Object Document Mapping ) -> a technique that maps between an object model in an application and a document database\n\ud83d\udd3b NoSQL Database (\nMongoDB\n) & CDC (Change Data Capture) pattern\n-> Tracks data changes log them, and queues messages for real-time system updates\n-> The clean data is stored in a NoSQL database\n\ud83d\udd3b Feature Pipeline\n->A streaming ingestion pipeline is part of the feature pipeline that processes Articles, Posts, and Code.\n->Tools like\nBytewax\nand\nSuperlinked\nare used, likely for further data processing and transformation.\n->This processed data is then queued in\nRabbitMQ\n, a message broker that helps in asynchronous processing and communication between different services.\n\ud83d\ude4c STAY TUNED, guys. On 23rd March, we unleash the second lesson of the\nhashtag\n#\nLLMTwin\ncourse by Decoding ML on\nMedium\n: \"The Importance of Data Pipelines in the Era of Generative AI\"!\nIf you want to learn more about the technologies used in this lesson check out:\n\ud83c\udfaf \ud835\udc49\ud835\udc52\ud835\udc50\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc37\ud835\udc4f:\nhttps://lnkd.in/dQ6kwC_Z\n\ud83c\udfaf \ud835\udc46\ud835\udc61\ud835\udc5f\ud835\udc52\ud835\udc4e\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc43\ud835\udc56\ud835\udc5d\ud835\udc52\ud835\udc59\ud835\udc56\ud835\udc5b\ud835\udc52:\nhttps://lnkd.in/dwV8sis2\n\ud83c\udfaf\u00a0\ud835\udc36\ud835\udc5c\ud835\udc5a\ud835\udc5d\ud835\udc62\ud835\udc61\ud835\udc52 \ud835\udc39\ud835\udc5f\ud835\udc4e\ud835\udc5a\ud835\udc52\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc58:\nhttps://lnkd.in/d5n_dt_n\n\ud83c\udfaf \ud835\udc40\ud835\udc52\ud835\udc60\ud835\udc60\ud835\udc4e\ud835\udc54\ud835\udc56\ud835\udc5b\ud835\udc54 \ud835\udc44\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52:\nhttps://www.rabbitmq.com/\n\ud83d\udd17 Check out the code on GitHub and support us with a \u2b50\ufe0f ->\nhttps://lnkd.in/dtTeZHN7",
        "image": "https://media.licdn.com/dms/image/D4D22AQHVF41WDTBUig/feedshare-shrink_800/0/1706604907163?e=1717027200&v=beta&t=nj1gzupPNnSzVp5MehQZluvFFJ2XBYSaJvzch-8QXV8"
    },
    "Post_11": {
        "text": "\u270d\ufe0f Did you know that you can build your own LLM Twin that sounds just like you?\n\ud83c\udf63 At a relatively recent sushi lunch, Paul Iusztin and I discussed the challenges of finding open-source resources for deploying large language models (LLMs) in production environments.\nI had a big \u201cAHA\u201d moment and I thought:\n\u201cWait, how awesome would it be if we were able to create an LLM Twin that would act like an AI writing assistant that can replicate your personality and tone of voice? That would be super helpful for the entire community of engineers that actively write specialized articles.\u201d \ud83e\udd14\n\ud83d\udca1 This conversation sparked the \ud835\udc13\ud835\udc21\ud835\udc1e \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc13\ud835\udc30\ud835\udc22\ud835\udc27 \ud835\udc02\ud835\udc28\ud835\udc2e\ud835\udc2b\ud835\udc2c\ud835\udc1e: \ud835\udc01\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d \ud835\udc18\ud835\udc28\ud835\udc2e\ud835\udc2b \ud835\udc0f\ud835\udc2b\ud835\udc28\ud835\udc1d\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27-\ud835\udc11\ud835\udc1e\ud835\udc1a\ud835\udc1d\ud835\udc32 \ud835\udc00\ud835\udc08 \ud835\udc11\ud835\udc1e\ud835\udc29\ud835\udc25\ud835\udc22\ud835\udc1c\ud835\udc1a.\n\ud835\udc13\ud835\udc21\ud835\udc1e \ud835\udc05\ud835\udc11\ud835\udc04\ud835\udc04 \"LLM Twin\" course, sponsored by \ud835\udc03\ud835\udc1e\ud835\udc1c\ud835\udc28\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc0c\ud835\udc0b, gives you the practical skills to build your own AI writing assistant that mimics your style and voice. \ufe0f\ud83e\udd16\nThe best part of this course? \u27a1\ufe0fYou will learn how to architect and build a real-world LLM system from start to finish \u2014 from data collection to deployment.\nYou will also learn to leverage MLOps best practices, such as experiment trackers, model registries, prompt monitoring, and versioning.\nHere\u2019s what this \ud835\udc21\ud835\udc1a\ud835\udc27\ud835\udc1d\ud835\udc2c-\ud835\udc28\ud835\udc27 \ud835\udc1c\ud835\udc28\ud835\udc2e\ud835\udc2b\ud835\udc2c\ud835\udc1e will teach you:\n\ud83d\udcc1  Data Collection Pipeline (AWS): Gather & clean your social media data using ETL pipelines.\n\u2699\ufe0f Feature Pipeline: Process data in real-time with Bytewax & Superlinked, then store it in a Qdrant vector DB.\n\u2699\ufe0f Training Pipeline: Train your LLM with QLoRA & Comet ML's experiment tracking, saving the best model.\n\ud83d\udc7e Inference Pipeline: Deploy your fine-tuned LLM as a REST API & enhance prompts with RAG for creative content generation. Monitor performance with Comet ML.\n\ud83d\udc47This course is designed for:\n- ML Engineers\n-Data Engineers\n-Data Scientists\n-Software Engineers\nProvided to you by the Decoding ML umbrella:\nPaul Iusztin\n| Senior ML & MLOps Engineer\nAlex Vesa\n| Senior AI Engineer\nAlexandru Razvant\n| Senior ML & MLOps Engineer\nWe couldn\u2019t create this course without the help and support of:\n\ud83d\udd34\nBytewax\n\ud83d\udd34\nQwak\n\ud83d\udd34\nSuperlinked\n\ud83d\udd34\nComet\n\ud83d\udd34\nQdrant\nWith that being said, I hope you are all on board to join us on our Medium & Substack channels and stay tuned for a 11-lesson practical experience!\nWho\u2019s UP for this challenge? \ud83d\ude4c",
        "image": "https://media.licdn.com/dms/image/D4D22AQFc8oze1uUWZw/feedshare-shrink_800/0/1706170386092?e=1717027200&v=beta&t=t4ZR8lZhif7vIdugOoTyPDXqy44lKwN0FrAD-IySUmg"
    },
    "Post_12": {
        "text": "\ud835\udde7\ud835\uddf5\ud835\uddf6\ud835\ude00 \ud835\uddf6\ud835\ude00 \ud835\uddf5\ud835\uddfc\ud835\ude04 you can achieve real-time capabilities of a RAG system.\n\ud835\uddd4\ud835\uddf9\ud835\ude04\ud835\uddee\ud835\ude06\ud835\ude00, the \ud835\uddf3\ud835\uddf6\ud835\uddff\ud835\ude00\ud835\ude01 \ud835\ude00\ud835\ude01\ud835\uddf2\ud835\uddfd is to think what components are needed for the system.\nThe system design is one of the most important steps in any software engineering process.\n\ud835\uddd4\ud835\uddf9\ud835\ude04\ud835\uddee\ud835\ude06\ud835\ude00, build the system with these things in mind:\n\ud83c\udfaf Scalability: The system's architecture is built with scalability in mind, ensuring it can handle growing data volumes and user queries without performance degradation\n\ud83c\udfaf Data Synchronization\n\ud83c\udfaf Data processing: The design includes efficient data ingestion, cleaning, chunking, and embedding processes\n\ud83c\udfafAdapts to Diverse Data Sources: The modular and flexible nature of the system design makes it easy to extend and adapt to various data sources beyond social media, underscoring its versatility.\nPaul Iusztin\nwrote an amazing and very detailed article in Decoding ML where he:\n-Demonstrated with a real-world example(Linkedin posts) how to design a real-time retrieval system\n\ud835\ude0f\ud835\ude26\ud835\ude33\ud835\ude26 \ud835\ude2a\ud835\ude34 \ud835\ude38\ud835\ude29\ud835\ude22\ud835\ude35 \ud835\ude3a\ud835\ude30\ud835\ude36 \ud835\ude38\ud835\ude2a\ud835\ude2d\ud835\ude2d \ud835\ude2d\ud835\ude26\ud835\ude22\ud835\ude33\ud835\ude2f \u2193\nReal-time streaming pipeline for up-to-the-minute data sync \ud83d\udd04\nAdvanced preprocessing for LinkedIn posts to enhance data quality \ud83e\uddfc\nA retrieval client that queries with high precision \ud83d\udd0d\nAccuracy boost using a rerank pattern and visualization with UMAP for deeper insights \ud83d\udcca\n\ud83e\uddd9\u200d\u2640\ufe0f The magic of this article lies in the adaptable framework and patterns we've presented, which can effortlessly be extended beyond social media data to embrace a wide array of data types.\n\ud835\uddd6\ud835\uddf5\ud835\uddf2\ud835\uddf0\ud835\uddf8 \ud835\uddf6\ud835\ude01 \ud835\uddfc\ud835\ude02\ud835\ude01 \ud835\uddfc\ud835\uddfb \ud835\uddd7\ud835\uddf2\ud835\uddf0\ud835\uddfc\ud835\uddf1\ud835\uddf6\ud835\uddfb\ud835\uddf4 \ud835\udde0\ud835\udddf\n\u2193\u2193\u2193\nhttps://lnkd.in/dmuqPfru",
        "image": "https://media.licdn.com/dms/image/D4D22AQEJ5zlP6qWrLQ/feedshare-shrink_800/0/1705922410332?e=1717027200&v=beta&t=3W9X4mt4JmQD4JViRqkQOnUgM8C0HubSvQaGruTgqhY"
    },
    "Post_13": {
        "text": "In today's tech-driven world, summarizing documents has become deceptively simple.\nJust a call to OpenAI's API, and voil\u00e0 \u2013 you have a summary. But what about when things get complex?\n\ud83d\udd0d The Real Challenge Begins in Production-Ready Environments\nConsider these scenarios:\n1. No Access to OpenAI API: What if you're restricted from using it?\n2. Alternative LLMs: How do you adapt to private LLMs like Llama2-7b or Mixtral-7b?\n3. Context Window Limitations: What if your document exceeds the LLM's context window?\nThese are valid concerns, but let's talk about a crucial aspect:\n\ud83e\udd14 Evaluating the Output of a Private LLM Summary Task\nA common pitfall in LLM-based summarization is the tendency to \"hallucinate\" \u2013 introducing non-existent information. So, how do we mitigate this?\nStrategies for Ensuring Quality Summaries:\n1. Prompt Techniques: Fine-tuning prompts to align with desired outputs.\n2. Summary Metrics: Metrics to evaluate summary quality.\n3. LLM Evaluator: A larger LLM, Llama2-13B or Mixtral-13B instructed to evaluate the summaries based on Accuracy, Relevance, and Adherence.\n4. Human Feedback: Integrating human judgment for final validation.\n\ud83d\udc68\ud83c\udffe\u200d\ud83d\udcbb In my professional journey, I've developed a composed summary metric focusing on three key aspects: Accuracy, Relevance, and Adherence.\n\ud83c\udfaf Accuracy\nScore 0: We avoid summaries with significant inaccuracies or misleading information.\nScore 1: We aim to improve summaries that are not fully accurate for reliable information extraction.\nScore 2: Our goal is to achieve highly accurate summaries that capture the main points with only minor inaccuracies that don't impede understanding.\n\ud83d\udd0d Relevancy\nScore 0: We discard summaries that are completely irrelevant and lack meaningful information.\nScore 1: We refine somewhat relevant summaries but miss some main themes of the document.\nScore 2: We strive for highly relevant summaries, encapsulating all main themes with precision.\n\ud83d\udcd0 Adherence\nScore 0: We reject summaries that completely disregard the document's structure and content.\nScore 1: We work on summaries with major adherence issues to reach a coherent structure.\nScore 2: We aspire to create summaries that perfectly adhere to the document's structure, mirroring its logical flow with precision.\nLLM evaluator and Human Feedback based on these summary metrics play a crucial role in assuring the quality of LLM summary tasks.\nFrom your experience, how do you evaluate the summary task of LLMs?",
        "image": "https://media.licdn.com/dms/image/C4D22AQEt4ApgJK2cWA/feedshare-shrink_800/0/1668848767383?e=1717027200&v=beta&t=0tD3_qB1_1iNHYGidvXj4qzFzqXUqZW7GP81g18mnOg"
    },
    "Post_14": {
        "text": "\ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \u201cYou don\u2019t need to evaluate the LLM tasks.\u201d\nIt was my first thought when I started to design a complex system based on 3 tasks: summarization, classification, and entity extraction.\n\ud83e\udd76 With big clients and thrilling projects on the horizon, the weight of responsibility grew heavier. It prompted a hard question:\nHow can I guarantee a workflow that evaluates the output of the Large Language Model(LLM ) system effectively and progresses toward autonomy over time?\n\ud83d\udc68\ud83c\udffe\u200d\ud83d\udcbb Here\u2019s the blueprint of the system I architected:\n\u27a1\ufe0f Step 1: Document Digitization The documents are digitalized using an OCR system, extracting the relevant information like text, pages, and tables.\n\u27a1\ufe0f Step 2: AI System Integration with Llama2-7B Core:\nAI Summarization: Efficiently condenses complex information, ensuring key insights remain intact.\nAI Entity Extraction: Accurately identifies and categorizes over 20 distinct entities within the documents.\nAI Classification: Classify the document based on its label (invoice, contract, and many others)\n\u27a1\ufe0f Step 3: Data Storage and Refinement The refined data is then securely housed in Amazon DynamoDB, ensuring easy access and retrieval while maintaining data integrity.\n\u27a1\ufe0f Step 4: Streamlit and Human Evaluation Interface To add a layer of quality assurance, we introduced the Streamlit Data Labeling Interface. It serves as a platform for human evaluators to oversee and validate the AI's conclusions, combining the precision of human oversight with the efficiency of AI.\n\u27a1\ufe0f Step 5: LLM Evaluator Integration A Large Language Model (LLM) Evaluator is deployed to cross-examine the AI's work. This dual-layer evaluation - both human and AI-driven - ensures our system's output stands up to the highest quality. The end goal here is to have an autonomous LLM evaluator that can run periodically and tell us if something wrong is happening.\n\u27a1\ufe0f Step 6: Refined Data\nHuman-refined data is stored for ongoing system enhancement, focusing on fine-tuning and RAG applications.\nIn conclusion, the key takeaway from our system's development underscores the indispensable role of human intervention in evaluating LLM outputs within a production environment. Maintaining a periodic check on these outputs is crucial for ensuring the gradual progression of our LLM evaluator towards autonomy.\n\u2753I\u2019m curious. How do you evaluate the LLM output in a production environment?",
        "image": "https://media.licdn.com/dms/image/C4D22AQGtPAs8iS6aCw/feedshare-shrink_2048_1536/0/1668604251602?e=1717027200&v=beta&t=0H2PgtW87YTUTeck-AaiJ71qRAnUpnFtMhkiSZwEJkw"
    },
    "Post_15": {
        "text": "\ud83d\udcb8 How to become a millionaire in 2024? A Sunday perspective\nNo, this is DEFINITELY not a guide to making your first million \ud83e\udd11. I'm not a fan of that kind of script.\nI once had a mentor who told me this: \u201c\ud835\udc06\ud835\udc1a\ud835\udc22\ud835\udc27 \ud835\udc24\ud835\udc27\ud835\udc28\ud835\udc30\ud835\udc25\ud835\udc1e\ud835\udc1d\ud835\udc20\ud835\udc1e, \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc26\ud835\udc28\ud835\udc27\ud835\udc1e\ud835\udc32 \ud835\udc30\ud835\udc22\ud835\udc25\ud835\udc25 \ud835\udc1c\ud835\udc28\ud835\udc26\ud835\udc1e \ud835\udc1a\ud835\udc1f\ud835\udc2d\ud835\udc1e\ud835\udc2b.\u201d\nNow, I\u2019m being honest, this \ud83c\udfce\ufe0f fast-paced era we are living in is crazy sometimes (I say that even if I\u2019m an innovation enthusiast).\nWe are caught up in a ping-pong of offers, choices, opportunities, and of course\u2026money.\nI\u2019m going to ask you 2 questions:\nIs every option an opportunity?\nWhere does \ud83d\udc49\u201cI want more\u201d? stand, and when do you conclude that \ud83d\udc49\u201cIt\u2019s enough\u201d.\nBeing young and ambitious, I\u2019ve always searched for \u201cmore\u201d.\nNot necessarily more money, but building knowledge and working with different people in different areas of my domain.\nDiscovery is the best pleasure and feeling great at what you do. And that\u2019s the feeling you\u2019re probably searching for too, deep down.\nOver the years I realized that there must be a balance between money, passion, and perspectives.\nI\u2019m a little bit subjective because I\u2019m obsessed with building and creating things with people that inspire me. I sometimes tend to sacrifice money for the greater good, because, in the end, I just want a balance that keeps me going, that keeps my drive on a high note! \ud83e\uddbe\nHere are my top inner \u201creality - check\u2019s \u201c:\n\u27a1\ufe0f Does it affect my inner peace/energy?\n\u27a1\ufe0f How does it contribute to my personal and professional development?\n\u27a1\ufe0f Does it help me upgrade my weak points?\nI encourage everyone to take as many opportunities as they can, but in the end, the only thing that will help you move forward is knowledge and people.\n\ud835\udc05\ud835\udc22\ud835\udc27\ud835\udc1d \ud835\udc32\ud835\udc28\ud835\udc2e \ud835\udc28\ud835\udc30\ud835\udc27 \ud835\udc26\ud835\udc1e\ud835\udc1c\ud835\udc21\ud835\udc1a\ud835\udc27\ud835\udc22\ud835\udc2c\ud835\udc26 \ud835\udc2d\ud835\udc21\ud835\udc1a\ud835\udc2d \ud835\udc20\ud835\udc1e\ud835\udc27\ud835\udc1e\ud835\udc2b\ud835\udc1a\ud835\udc2d\ud835\udc1e\ud835\udc2c \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc1b\ud835\udc1a\ud835\udc25\ud835\udc1a\ud835\udc27\ud835\udc1c\ud835\udc1e: \ud835\udc29\ud835\udc1a\ud835\udc2c\ud835\udc2c\ud835\udc22\ud835\udc28\ud835\udc27, \ud835\udc26\ud835\udc28\ud835\udc27\ud835\udc1e\ud835\udc32, \ud835\udc1a\ud835\udc27\ud835\udc1d \ud835\udc29\ud835\udc1e\ud835\udc2b\ud835\udc2c\ud835\udc29\ud835\udc1e\ud835\udc1c\ud835\udc2d\ud835\udc22\ud835\udc2f\ud835\udc1e\ud835\udc2c.\nI\u2019m curious.\nFor you, where is the fine line between \u201cIt\u2019s enough\u201d and \u201cI want more\u201d \u2753",
        "image": "https://media.licdn.com/dms/image/C4D22AQFI4k39io_GHA/feedshare-shrink_800/0/1663584756399?e=1717027200&v=beta&t=zGq5uG_NAmsRmM_dHEbWTbPQlgA2UjDWou3RQeVj7bc"
    },
    "Post_16": {
        "text": "\ud83e\udd2d You don\u2019t need to check OCR system output quality.\nWhat a joke right?\nText Extraction is the core of any RAG application where you want to have the best experience in talking to your documents.\n\ud83d\udd3a I\u2019ve seen several RAG applications where the text extraction quality is not checked.\n\ud83d\udd3a When we talk about millions of documents per day, the text extraction quality becomes crucial\nIn my daily work, when I deal with OCR systems, I use 2 LLM components to evaluate and correct the text extraction:\n1\ufe0f\u20e3 LLM Evaluator - this component is used to evaluate the text from deep-learning-based OCR systems like PyTesseract or EasyOCR\n2\ufe0f\u20e3 LLM Correct Text Extraction - this component is used to correct the final text (grammatical error)\nHow these 2 components are integrated into an OCR system workflow?\nHere\u2019s my approach:\n\ud83d\udcc4 Starting with source documents\n\ud83d\udc0d using Python PDF tools for initial extraction\n\ud83d\udc40 conducting a readability check\n\ud83e\udd16 enhancing with OCR tools like PyTesseract/EasyOCR\n\ud83d\udcca reviewing OCR results and parameters\n\ud83e\udde0 employing a Language Model Evaluator for accuracy\n\ud83d\udd01 iterating through a feedback loop for improvements\n\u2699\ufe0f fine-tuning OCR settings\n\ud83d\udd04 double-checking with LLM post-OCR\n\ud83c\udf1f producing a refined, accurate, and clear output, ready for application.\u201d\nI\u2019m curious - how are you ensuring accuracy in your text extraction processes?",
        "image": "https://media.licdn.com/dms/image/C4D22AQF29CuGCtK1vw/feedshare-shrink_800/0/1663584757328?e=1717027200&v=beta&t=AFacAWC-GKP2OR7j4cm7HOPX--tEECy0eLQh1lgzrDY"
    },
    "Post_17": {
        "text": "Backend Engineering IS NOT AI Engineering. \ud83e\udd10\n\u201c\ud835\udc7e\ud835\udc89\ud835\udc82\ud835\udc95 \ud835\udc8a\ud835\udc94 \ud835\udc95\ud835\udc89\ud835\udc86 \ud835\udc87\ud835\udc8a\ud835\udc8f\ud835\udc86 \ud835\udc8d\ud835\udc8a\ud835\udc8f\ud835\udc86 \ud835\udc83\ud835\udc86\ud835\udc95\ud835\udc98\ud835\udc86\ud835\udc86\ud835\udc8f \ud835\udc83\ud835\udc82\ud835\udc84\ud835\udc8c\ud835\udc86\ud835\udc8f\ud835\udc85 \ud835\udc86\ud835\udc8f\ud835\udc88\ud835\udc8a\ud835\udc8f\ud835\udc86\ud835\udc86\ud835\udc93\ud835\udc8a\ud835\udc8f\ud835\udc88 \ud835\udc82\ud835\udc8f\ud835\udc85 \ud835\udc68\ud835\udc70 \ud835\udc86\ud835\udc8f\ud835\udc88\ud835\udc8a\ud835\udc8f\ud835\udc86\ud835\udc86\ud835\udc93\ud835\udc8a\ud835\udc8f\ud835\udc88?\u201d\nI was asked this question yesterday at an interview, and my mind froze for a couple of minutes.\nI realized that working in multiple startups has made me wear many hats \ud83e\udd20 \u2013 from software and backend engineering to AI expertise and even the CTO role. This journey has taught me the art of adaptability, always ready to jump into any challenge that comes my way.\nBut that doesn\u2019t mean that\u2019s the only path of evolution you can have as an engineer. There are also drawbacks to following a multi-perspective technical journey:\n\u2666\ufe0f You get into too many roles and responsibilities and forget the details;\n\u2666\ufe0f You get distracted by soaking up a lot of information in different domains;\n\u2666\ufe0f Sacrifice quality to accumulate quantity.\nFinally, my answer to this interview was a personal experience opinion.\nThere\u2019s a fine line between backend and AI engineering, and it depends on the following question:\n\ud835\udc16\ud835\udc21\ud835\udc1a\ud835\udc2d \ud835\udc1a\ud835\udc2b\ud835\udc1e \ud835\udc30\ud835\udc1e \ud835\udc1b\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20\u2753 \ud835\udc00\ud835\udc27 \ud835\udc0c\ud835\udc15\ud835\udc0f \ud835\udc28\ud835\udc2b \ud835\udc1a \ud835\udc0f\ud835\udc2b\ud835\udc28\ud835\udc1d\ud835\udc2e\ud835\udc1c\ud835\udc2d \u2753\nIn an MVP setting, blending backend and AI engineering is more common. Quick, functional prototypes are key, requiring a broad skill set.\nHowever, for an advanced product, the distinction is clearer.\n\u2699\ufe0f Backend engineering focuses on building a robust, scalable infrastructure - the foundation essential for AI implementation.\n\ud83e\udd16 AI Engineering, meanwhile, involves developing intelligent algorithms that leverage this infrastructure, transforming data into actionable insights and advanced features.\nThere's indeed an overlap in technical skills, but backend and AI engineering divide in their core objectives and contributions to the product\u2019s lifecycle.\nThe backend lays the groundwork, \u26d3\ufe0f while AI brings the innovation.\n\ud83e\udde0 \ud835\udc0b\ud835\udc1e\ud835\udc2d \ud835\udc26\ud835\udc1e \ud835\udc24\ud835\udc27\ud835\udc28\ud835\udc30 \ud835\udc32\ud835\udc28\ud835\udc2e\ud835\udc2b \ud835\udc2d\ud835\udc21\ud835\udc28\ud835\udc2e\ud835\udc20\ud835\udc21\ud835\udc2d\ud835\udc2c!\nWhat do you consider to be a role differentiator between a backend engineer and an AI engineer?\nhashtag\n#\naiengineering\nhashtag\n#\nartificialintelligence\nhashtag\n#\naiengineer",
        "image": "https://media.licdn.com/dms/image/C4D22AQF6bjTc3nUjgQ/feedshare-shrink_800/0/1663584756459?e=1717027200&v=beta&t=pBYfBM5BZd6k2p8vEHNmzBKSVFY5uiAbkcDmjFNn5Jo"
    },
    "Post_18": {
        "text": "Is it hard for you to choose the best-fitting OCR system, based on the text extraction quality, hardware requirements, and processing time constraints? \ud83e\udd14\nThere are multiple open-source libraries and OCRs like \ud83d\udc49 PyPDF, Tesseract or EasyOCR.\nRegarding speed, flexibility, and HW constraints, the first choice is the PyPDF loader from @langhcain or the PyPDF module directly in our Python code which runs a document in milliseconds on the CPU.\nBut have you tested the quality of text extraction? As AI engineers, it\u2019s our job to check the quality of this task.\n\u274c PyPDF fails to extract the text for scanned or low-quality documents.\nSelecting the right OCR tool involves balancing speed and accuracy. PyPDF excels in speed but may struggle with quality in certain documents.\n\ud83d\udca1 A Readability Algorithm can be a game-changer in deciding what OCR we should use.\n\ud83e\udde0 \ud835\udddc\ud835\uddfb\ud835\ude01\ud835\uddff\ud835\uddfc\ud835\uddf1\ud835\ude02\ud835\uddf0\ud835\uddf6\ud835\uddfb\ud835\uddf4 \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\udde5\ud835\uddf2\ud835\uddee\ud835\uddf1\ud835\uddee\ud835\uddef\ud835\uddf6\ud835\uddf9\ud835\uddf6\ud835\ude01\ud835\ude06 \ud835\uddd4\ud835\uddf9\ud835\uddf4\ud835\uddfc\ud835\uddff\ud835\uddf6\ud835\ude01\ud835\uddf5\ud835\uddfa:\n1. Merge & Standardize: It consolidates OCR text fragments and standardizes them, preparing the text for analysis.\n2. Detect Non-Text Elements: The algorithm identifies non-textual characters, crucial for assessing text purity.\n3 . Red Flags: It checks for indicators of unreadability, adding depth to the analysis.\n4. Weigh & Score: Each aspect is evaluated and scored to determine text readability.\n5. Final Verdict: This score is compared against a set threshold to decide if the text is readable.\n\ud83d\udcca Empirical thresholds guide your algorithm in routing documents. Clear texts are stored in your S3 bucket for immediate use. Those failing the test are escalated to Pytesseract or EasyOCR for more intensive processing.\nThis approach ensures you don't just process documents rapidly; you ensure their quality remains accurate.\nWe're not just digitizing text; we're curating knowledge with precision.\n\ud83d\udcac \ud835\uddec\ud835\uddfc\ud835\ude02\ud835\uddff \ud835\udde7\ud835\uddf5\ud835\uddfc\ud835\ude02\ud835\uddf4\ud835\uddf5\ud835\ude01\ud835\ude00?\nAre you facing similar challenges in document processing?\nHow do you balance speed and accuracy in your OCR solutions?\nLet's discuss this in the comments below!",
        "image": "https://media.licdn.com/dms/image/C4D22AQE1gtKrS4I3dg/feedshare-shrink_2048_1536/0/1663239252989?e=1717027200&v=beta&t=hwgEXj160Yf3JwWUbA0spckHqVP7O7MmxmEeMVyvFcc"
    },
    "Post_19": {
        "text": "How to build a Social Media Content Generator that works\nI am sharing my step-by-step mini-guide that\u2019s going to help you build a \ud83d\udc7eSocial Media Content Generator.\nOne that works! \ud83d\ude0f\nWriting instructions for OpenAI's GPT API might seem straightforward, but the real challenge lies in designing scalable, effective prompt templates, especially for a diverse clientele.\nI wanted to give a practical example from my professional experience, so I picked \ud83d\udc49\nBookingham\n, a dynamic booking platform that collaborates with hundreds of restaurants.\nAnd man, that content needs to be provided continuously, on a variety of social media channels and needs to keep various writing styles, tones of voice, and brand statements.\n\ud83d\udd0dSo here\u2019s the challenge: How to craft individualized and captivating social media content for each restaurant, scalable across hundreds of clients?\n\ud83d\udfe2 Below you can tap into my\nhashtag\n#\nstrategy\nmind-map: A double-perspective approach \u27a1\ufe0f Business Discovery and Product Discovery, leading to the development of versatile prompt templates.\n\ud83d\udfe2 After I take you into the steps for business discovery and product discovery, I am unveiling my 3 staple phases in which I develop my AI product and its way of thinking and writing. \ud83e\udde0\n\ud83d\udfe2 I am also sharing a diagram example I use that will guide you through the whole given example for Bookingham.\nRemember! This is the development phase. You need to test everything, according to your industry and type of content generator. I keep that as a future topic.\nLet me know if this is helpful for you!\nhashtag\n#\nAI\nhashtag\n#\nOpenAI\nhashtag\n#\nDigitalMarketing\nhashtag\n#\ncontentgenerator\nhashtag\n#\naicontent\nhashtag\n#\naiproducts",
        "image": "https://media.licdn.com/dms/image/C5622AQGoZEpJdGVQmA/feedshare-shrink_800/0/1662560346849?e=1717027200&v=beta&t=zNAEAFuhY4OeYgC8HbOOQenZZBWUZQWgnZDB1GdwHnk"
    },
    "Post_20": {
        "text": "\ud83d\ude80 Exploring the frontier of private LLM deployment with AWS SageMaker in my latest article on Llama2-7b-chat \ud83c\udf10\n\ud83d\udd0d Dive deep with me in \"Introduction to Deploying Private LLMs with AWS SageMaker\" where I unpack the complexities of deploying Llama2-7b-chat.\n\ud83d\udccc What You'll Discover:\n\u2192 AWS SageMaker's role in revolutionizing ML deployment, balancing scalability with robust security.\n\u2192 Unraveling Llama2-7b-chat: A leap in AI communication, powered by extensive 2T token training.\n\u2192 A meticulous walkthrough of the deployment process, from environment setup to execution.\n\ud83d\udd27 From Theory to Practice:\n\u2192 Follow my detailed guide on configuration,\nHugging Face\nintegration, and effective inference strategies.\n\u2192 Experience the perfect blend of theoretical knowledge and practical application in deploying LLMs using\nAmazon SageMaker\n.\n\ud83c\udf1f Why This Matters: In today's tech-driven world, knowing how to manage private LLMs like Llama2 and preparing for cloud-based solutions are vital. The AWS SageMaker and Hugging Face LLM DLC are essential for achieving these skills and navigating the AI landscape effectively.\n\ud83d\udca1 Read the full article here \u2192\nhttps://lnkd.in/duSYpK22\n#DecodeML#AWS#Sagemaker#AI#LLM#Llama2#HuggingFace",
        "image": "https://media.licdn.com/dms/image/C5622AQEt6jcjw78yvw/feedshare-shrink_800/0/1662560347339?e=1717027200&v=beta&t=kqPockk0Or8aeTLaqwYf2yz1U209JFo3gMKCVdMrvjc"
    },
    "Post_21": {
        "text": "\ud83e\udd14 Poate Inteligen\u021ba Artificial\u0103 s\u0103 preia controlul?\nDeja o face. Este \u00een buzunarul nostru, pe ecranul din camer\u0103, pe pontatorul de la serviciu sau \u00een co\u0219ul de cump\u0103r\u0103turi de la Emag.\n\u0218i totusi, nu acesta este subiectul pe care vreau sa-l discut, ci mai degrab\u0103 cum ar putea Inteligen\u021ba Artificial\u0103 s\u0103 preia controlul \u00eentr-un mod asumat, ajut\u00e2ndu-ne pe noi ca indivizi.\nAud foarte des afirma\u021biile: \u201cAI-ul \u00eemi va lua locul.\u201d, \u201cAI-ul este r\u0103u\u201d, \u201cAI-ul este de ne\u00eeneles.\u201d etc. \u00centr-adev\u0103r, s-a creat o utopie \u00een jurul AI-ului, de parc\u0103 traim un nou episod din \u201cBrave new world\u201d. Dar hai s\u0103 tr\u0103im episodul din prezentul actual, prezentul t\u0103u sau prezentul meu.\nInteligen\u021ba artificial\u0103 este creat\u0103 de un grup de oameni pentru un anumit scop. Dac\u0103 scopul ini\u021bial se schimb\u0103, acest fapt este tot rezultat oamenilor.\n\ud83e\udd16 Harner Slack, de la Harvard Medical School afirm\u0103: \u201cDac\u0103 un doctor poate poate fi \u00eenlocuit de un computer, atunci el sau ea merit\u0103 s\u0103 fie \u00eenlocuit/\u0103 de computer..\u201d . O afirma\u021bie acid\u0103, care intrig\u0103 \u0219i declan\u0219eaz\u0103 un conflict \u00eempotriv\u0103 a tot ce \u00eenseamn\u0103 computer, tehnologie, digitalizare sau Inteligen\u021b\u0103 artificial\u0103.\nLu\u0103m o gur\u0103 de aer, respir\u0103m un pic \u0219i apoi ne im\u0103gin\u0103m. Cum \u00eenva\u021b\u0103 inteligen\u021ba artificial\u0103? Este ca un copil mic care are nevoie de \u00eendrumarea celor mai mari, adic\u0103 de experien\u021ba lor. AI-ul, \u00een radioterapie sau radiologie de exemplu, va \u00eenv\u0103\u021ba din experien\u021ba acelor doctori. Scopul? \u00cen timp s\u0103 devin\u0103 real ajutor pentru ace\u0219tia, gener\u00e2nd solu\u021bii \u0219i ipoteze la care un om nu are mereu acces \u00een mod con\u0219tient. \u00cen medicin\u0103, AI-ul poate deveni cel mai bun prieten al medicului, u\u0219urandu-i munca repetitiv\u0103, fiind al treilea lui ochi atunci cand obose\u0219te.\n\ud83c\udf0e Am \u00een\u021beles \u00een timp c\u0103 inteligen\u021ba artificial\u0103 este ca un tool care ne simplific\u0103 via\u021ba, care provoac\u0103 la evolu\u021bie. Oamenii sunt obi\u0219nui\u021bi sau programa\u021bi s\u0103 evolueze atunci c\u00e2nd ies din zona de confort sau din simpla competi\u021bie cu altcineva. Dac\u0103 privim deschis c\u0103tre aceasta idee, AI-ul ne poate provoca, pe noi ca oameni s\u0103 evolu\u0103m, s\u0103 ne dorim mai mult.\nAI-ul, \u00eenv\u0103\u021b\u00e2nd din experien\u021bele a unor mii de oameni, va g\u0103si solu\u021bii la care noi ca indivizi nu ne-am gandi. \u0218tim cu to\u021bii c\u0103 energia unui grup este mai mare decat energia unui singur individ.\nEste alegerea noastr\u0103 cum putem l\u0103sa AI-ul s\u0103 ne ajute \u0219i este tot alegerea noastr\u0103 s\u0103 distingem rolul propriu \u00een care ac\u021bion\u0103m.\nDeci, dac\u0103 defapt ne e  team\u0103 de a pierde controlul asupra evolu\u021biei omenirii, v\u0103 \u00eentreb acum, cine de\u021bine cu adev\u0103rat controlul?",
        "image": "https://media.licdn.com/dms/image/C5622AQGlvnTXyoo8_Q/feedshare-shrink_2048_1536/0/1662560343622?e=1717027200&v=beta&t=P9c924h6XNCzRQPiYI0jTX9jDrEohZGAzz6QWfegCfg"
    },
    "Post_22": {
        "text": "\ud83d\udcb2Check out our crowdfunding campaign.\n\ud83c\udf0eYou can be part of\nAIMINDED\nvision with just a single click !\nhashtag\n#\nartificialintelligence\nhashtag\n#\ncrowdfunding",
        "image": "https://media.licdn.com/dms/image/C5622AQG-6V91L-Zk5w/feedshare-shrink_800/0/1662560346995?e=1717027200&v=beta&t=5J97mIot9Zi2WaJrFjRdx7j_M4uFMOt8SKLavcdDVuA"
    },
    "Post_23": {
        "text": "\ud83c\udf89 We are off to a great start! Our first investment is here!\n\ud83d\udcafNow you have the chance to be on the PRIORITY LIST, in the\nhashtag\n#\ncrowdfunding\ncampaign that we started with\nR\u014dnin\n!\n\u2757\ufe0fAt the end of the week, the campaign will be LIVE and anyone will be able to invest in our startup, with the amount of min. 100\u20ac!\n\ud83d\udd3bIf you are interested in being part of the investors of a successful\nhashtag\n#\nMedTech\nbusiness, NOW IT'S THE RIGHT TIME!\ud83d\udc47\ud83d\udc47\nhttps://lnkd.in/d-KfdgCu\n\ud83d\udd3bLearn more about AIMINDED:\nhttps://aiminded.ro/\nhashtag\n#\ncrowdfunding\nhashtag\n#\ncrowdfundingcampaign\nhashtag\n#\ninvestment\nhashtag\n#\ninvestmentopportunity\nhashtag\n#\ninvest\nhashtag\n#\ninvesting\nhashtag\n#\nstartup\nhashtag\n#\nartificialintelligence\nhashtag\n#\ntechnology",
        "image": "https://media.licdn.com/dms/image/C5622AQFUqzyg6ipQ0A/feedshare-shrink_800/0/1650555189267?e=1717027200&v=beta&t=h8WqgotGObJwghY85rjEJAQ-Tz0n7KeLpuDlxPryZE4"
    },
    "Post_24": {
        "text": "\ud83e\udd29 We are ON to something BIG!\nhashtag\n#\ncomingsoon\n\u2755We are getting ready for starting our first\nhashtag\n#\ncrowdfunding\ncampaign, along with the\nR\u014dnin\nplatform!\nTogether we can be one step closer to achieving our mission: \ud83d\udd2c accelerate cancer treatment through\nhashtag\n#\nartificialintelligence\n!\n\ud83d\udc49 Discover our story:\nhttps://lnkd.in/d-KfdgCu\nhttps://lnkd.in/dyFafJck\nhashtag\n#\ncrowdfundingcampaign\nhashtag\n#\nstartup\nhashtag\n#\nmedtech\nhashtag\n#\ninvestment\nhashtag\n#\nartificialintelligence",
        "image": "https://media.licdn.com/dms/image/C4D22AQHgnWxg3oHzaw/feedshare-shrink_800/0/1658228794815?e=1717027200&v=beta&t=wvlsD6MxOwryoid4J6dt7Rq4C1GQxvPZMtBT2Cia7yM"
    },
    "Post_25": {
        "text": "\u2753Ce \u00eenseamn\u0103 antreprenoriatul pentru tine?\n\ud83e\udde0 Cu aceast\u0103 \u00eentrebare mi-am propus s\u0103 provoc imagina\u021bia \u0219i min\u021bile unor studen\u021bi extraordinari care au participat la concursul Startup Survivor. Am r\u0103mas pl\u0103cut surprins de multitudinea de r\u0103spunsuri pe care le-am primit \u0219i m\u0103 simt inspirat s\u0103 \u00eemi adaug amprenta personal\u0103 asupra acestei \u00eentreb\u0103ri.\n\ud83d\udcb2Suntem \u00eenv\u0103\u021ba\u021bi s\u0103 asociem antreprenoriatul cu capitalul, profitul \u0219i performan\u021ba.\nAspectul care nu este predat \u00een \u0219coli este ce mentalitate trebuie s\u0103 ai pentru a ajunge antreprenor. Care este motiva\u021bia din spatele performan\u021bei tale?\nPentru mine, antreprenoriatul reprezint\u0103 un stil de viat\u0103, un crez cu care te treze\u0219ti  cu care adormi. Nu cred c\u0103 ne na\u0219tem antreprenori \u0219i, \u00een acelasi timp, nu cred ca antreprenoriatul se \u00eenva\u021b\u0103; nu exist\u0103 limit\u0103 de v\u00e2rst\u0103 sau educa\u021bie \u00een aceast\u0103 direc\u021bie.\nTrebuie \u00eens\u0103 s\u0103 fii foarte prezent \u0219i conectat la ce se \u00eent\u00e2mpl\u0103 \u00een jurul t\u0103u. Astfel, dob\u00e2ndim maturitatea de a g\u0103si solu\u021bii pentru probleme neexploatate.\nObt\u00e2nd pentru o astfel de g\u00e2ndire, antreprenoriatul te pune \u00een situa\u021bia inconfortabil\u0103 de a te cunoa\u0219te foarte bine pe tine \u00eensu\u021bi. Totul porne\u0219te de la cine e\u0219ti tu.\n\ud83d\udcd3 Introspec\u021bia devine cea mai puternic\u0103 \u2018arm\u0103\u2019 pe care noi ca antreprenori o putem avea \u00een procesul de g\u0103sire a unei solu\u021bii. Combinat\u0103 cu puterea de a visa, introspec\u021bia ne dezvolt\u0103 o tr\u0103s\u0103tur\u0103 specific\u0103 fiec\u0103rui antreprenor de succes: rezilien\u021ba.\nPentru mine aceast\u0103 c\u0103l\u0103torie se desf\u0103\u0219oar\u0103 ca o bucl\u0103 infinit\u0103, zi \u0219i noapte, \u00een care cred orbe\u0219te c\u0103 pot g\u0103si formula ideal\u0103 pentru a avansa, dar asta este lumea mea interioar\u0103. Lumea exterioar\u0103 m\u0103 \u00eenva\u021b\u0103 c\u0103 nu e a\u0219a. Azi prime\u0219ti un \u201cnu\u201d, maine prime\u0219ti un alt \u201cnu\u201d, iar procesul continu\u0103.\nPe h\u00e2rtie, destina\u021bia final\u0103 arat\u0103 frumos, \u00eens\u0103 ca antreprenor consider c\u0103 trebuie s\u0103 te \u00eendr\u0103goste\u0219ti de  acest proces, \u00een care e\u0219ti nevoit s\u0103 la\u0219i p\u0103r\u021bi din tine \u0219i s\u0103 te deschizi, pentru a primi deschidere.\nAntreprenoriatul construie\u0219te comunit\u0103\u021bi \u0219i business-uri care pot crea un impact, at\u00e2t \u00een lumea interioar\u0103 a fiec\u0103rui om, dar \u0219i \u00een exteriorul ce ne \u00eenconjoar\u0103. Totul devine un sistem mai puternic, \u00een care valorile comune primeaz\u0103.\nSemnat, un antreprenor la \u00eenceput de drum.\nMultumesc\nAndra Cara\npentru inspiratie.\nhashtag\n#\nbusiness\nhashtag\n#\nstartup\nhashtag\n#\nai\nhashtag\n#\nleadership",
        "image": "https://media.licdn.com/dms/image/C4D22AQFnnY8CvWRdMg/feedshare-shrink_800/0/1605114174121?e=1717027200&v=beta&t=sHkY20feHGuXzvOBZdaX2bnu6MIFzipZsOezRNnT0UE"
    },
    "Post_26": {
        "text": "It's not about winning. It's about gathering together great minds from the same ecosystem.\nThanks,\nNTT DATA Romania\nfor making us part of this ecosystem."
    },
    "Post_27": {
        "text": "\ud83e\uddec What is the synergy between human life and technology, and how can we use Artificial Intelligence to make our lives more human, in the medical spectrum?\nWe are glad to present our vision at\nNTT DATA Romania\nfor the Romania eAwards, and thank everybody who embraced it!\nOur participation at MedTech events and competitions shows how resilient we are in our development process. We are grateful for our team and medical body, who trust our work and perseverant state of mind!\nhashtag\n#\ntechnology\nhashtag\n#\nartificialintelligence\nhashtag\n#\nmedtech\nhashtag\n#\nstartup\nhashtag\n#\nradiotherapy"
    },
    "Post_28": {
        "text": "Pitching an idea isn't everything. Trusting your vision is.\nAIMINDED\nhashtag\n#\nradiotherapy\nhashtag\n#\nartificialintelligence\nhashtag\n#\nmedtech\nhashtag\n#\nstartup\nhashtag\n#\nvision\nhashtag\n#\nleadership"
    },
    "Post_29": {
        "text": "It was a pleasure to present the vision of AIMinded and how AI can change the entire cancer paradigm.\nhashtag\n#\nartificialintelligence\nhashtag\n#\nchange\nhashtag\n#\nradiotherapy"
    },
    "Post_30": {
        "text": "\ud83d\udccdIt's Industry Day at\nSSIMA Re:Imagine Healthcare\nand we are enjoying some awesome technology talks!\nAt 7 PM we are holding a pitch and Q&A session about AI in \ud83e\uddec Radiotheraphy and the value it brings in the cancer treatment process.\n\ud83d\udc41 We are ready to expand our vision with a great public in front of us.\nStay tuned!\nhashtag\n#\nai\nhashtag\n#\nhealthcare\nhashtag\n#\nstartup\nhashtag\n#\nmedtech\nhashtag\n#\nartificialintelligence\nhashtag\n#\nradiotherapy"
    },
    "Post_31": {
        "text": "\ud83c\udf10\nAIMINDED\nis at SSIMA!\nIt feels amazing to be attending a great environment of MedTech experts and presenting our StartUp in front of an inspirational audience of researchers.\n\ud83d\udc49We will open the event tomorrow, with a LIVE showcase of our product at Oradea Hospital, and in the evening we will discuss AIMINDED's mission and vision in the healthcare system.\nArtificial Intelligence saves lives, and we are here to prove it!"
    },
    "Post_32": {
        "text": "SSIMA Re:Imagine Healthcare & Oradea City Hall proudly announce SSIMA 2022: Medical Image Computing and Image-Assisted Robotic Surgery.\nIn close collaboration with our host, the City of Oradea, the SSIMA Organization Committee is inviting medical and engineering students, postgraduates and professionals to join us between the 5th and 9th of September this year at SSIMA 2022.\nIt will be an event hosted for the first time in the beautiful riverside City of Oradea, with its grand Art Nouveau architecture, parks and quaint town squares.\nThe perfect location for an academic event unparalleled in Eastern Europe, where top academics from the most renowned institutions from the USA, Israel, the Netherlands, UK and many more gather to share and discuss their latest discoveries during a weeklong schedule full of lectures, roundtable discussions, social events and practical hands-on sessions.\nThis year\u2019s edition will focus on Medical Image Computing and Image-Assisted Robotic Surgery. However, there will also be enough room for discussion and interaction with our invited speakers on other topics related to the state-of-the-art on related methods and clinical applications, as well as on fundamental academic skills in scientific writing and presentations, and grant writing tips.\nThe SSIMA Organization Committee and the City of Oradea look forward to welcoming you on 5th of September and will be opening the application process soon at\nwww.SSIMA.eu\n.\nSincerely,\nSSIMA Organization Committee\nProf.\nAlfred M. (Freddy) Bruckstein\n(\nTechnion - Israel Institute of Technology\n)\nProf.\nAlejandro F Frangi\n(\nUniversity of Leeds\n|\nKU Leuven\n)\nGeorge Haber\n(Crestafund Investments)\nDr. Elena Ovreiu (\nUniversity POLITEHNICA of Bucharest\n)\nProf.\nBart ter Haar Romeny\n(\nEindhoven University of Technology\n)\nProf.\nAlon Wolf\n(VP of\nTechnion - Israel Institute of Technology\n)\nOradea City Hall\nMayor of Oradea  Florin Birta\nCity Manager  Mihai Jurca"
    },
    "Post_33": {
        "text": "Utilizarea inteligen\u021bei artificiale pentru analiza datelor medicale cre\u0219te rapid. Acest webinar ofer\u0103 o privire asupra evolu\u021biilor recente \u0219i cum este aplicat\u0103 inteligen\u021ba artificial\u0103 \u00een radioterapie pentru furnizarea unor servicii de s\u0103n\u0103tate mai bine direc\u021bionate, centrate pe om.\nAl\u0103tur\u0103-te nou\u0103 joi, 21 iulie de la ora 16:00 pentru a afla despre cele mai bune practici.\nSpeakeri:\nVesa Alexandru - CEO AIMinded, Software Developer;\nFabian Jichi - Co-fondator AIMinded, Software Developer;\nMihai Zerbea - Doctor Specialist Radioterapie, Doctor Advisor la AIMinded.\nMai multe detalii despre eveniment:\nhttps://bit.ly/3yO8HE3\nPentru a participa te rug\u0103m s\u0103 te \u00eenregistrezi aici:\nhttps://bit.ly/3yQHLTZ\nTe a\u0219tept\u0103m!\nhashtag\n#\nartificialintelligence\nhashtag\n#\nmedical\nhashtag\n#\nradiotherapy\nhashtag\n#\nwebinar"
    },
    "Post_34": {
        "text": "Proud of our team!\nAndreea M.\n,\nFabian Jichi\n,\nRares Istoc\n,\nAndreea Gabriela Oros\n,\nNickolas Filip\n,\nCristian Predescu\nyou are awesome ."
    },
    "Post_35": {
        "text": "Digital technology and AI have the power to solve many of today\u2019s healthcare problems. At AIMinded we want to make this as accessible as possible and accelerate the treatment of cancer together.\nHealth Venture Lab\nteam and\nGE HealthCare\nexecutives believed in us and highlighted us in the top three most promising projects.\nRead more below!"
    },
    "Post_36": {
        "text": "Folow them . They are awesome !"
    },
    "Post_37": {
        "text": "Dac\u0103 g\u00e2nde\u0219ti ca un copywriter, \u00ee\u021bi po\u021bi intensifica \u00eentreaga strategie de afaceri.\nUn copywriter pune \u00eentreb\u0103ri. Care este cel mai important lucru de spus aici? Ce vrei s\u0103 realizeze oamenii dup\u0103 ce citesc acest text? Cum vrei s\u0103 se simt\u0103 oamenii? Copywriterii buni intr\u0103 \u00een capul cititorului ideal, la fel cum tu dore\u0219ti s\u0103 intri \u00een capul clientului t\u0103u ideal.\nG\u00e2nde\u0219te ca un copywriter \u0219i vei \u0219ti exact ce s\u0103 le transmi\u021bi oamenilor pe care \u00eei serve\u0219ti.\nCite\u0219te mai multe aici:\nhttps://lnkd.in/dfUMuet\nhashtag\n#\nmarketing\nhashtag\n#\ncontentmarketing\nhashtag\n#\ncopywriting"
    }
}